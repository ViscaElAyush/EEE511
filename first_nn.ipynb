{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf63091",
   "metadata": {},
   "source": [
    "Build a baseline model using the weather station data (this approach used all days in 2018 since the data was available).\n",
    "\n",
    "\n",
    "Then use the model to make predictions for the ENVI-met(micro-climate) data for that specific day and compare it to model predictions using weather station data also for the same day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a67839",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff5f4a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pickle\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "import csv\n",
    "\n",
    "import PyQt5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2323f8cd",
   "metadata": {},
   "source": [
    "# 2. Import Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d68606",
   "metadata": {},
   "source": [
    "## 2.1 Save csv files as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d25376",
   "metadata": {},
   "source": [
    "Only run this once to save our csv data as pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31c1e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> NO NEED TO RUN SAVED AS PICKLE FILES <--\n",
    "# WEATHER FILES ##\n",
    "\n",
    "# # AZ PHX Sky Harbor Data #\n",
    "AZW_15 = pd.read_csv(\"./Data/AZW_15.csv\")\n",
    "\n",
    "# # ENVIMET DATA #\n",
    "BPS = []\n",
    "Fname = []\n",
    "for path in pathlib.Path(\"./Data/BPS\").iterdir():\n",
    "    if path.is_file():\n",
    "        current_file = pd.read_csv(path)\n",
    "        BPS.append(current_file)\n",
    "        Fname.append(path.name.replace('.csv', ''))\n",
    "\n",
    "# # CAMPUS METABOLISM DATA #\n",
    "metabol14 = []\n",
    "for path in pathlib.Path('./Data/metabol14').iterdir():\n",
    "    if path.is_file():\n",
    "        current_file = pd.read_csv(path)\n",
    "        metabol14.append(current_file)\n",
    "\n",
    "# ## Drop last row of EnviMet Data\n",
    "for i in range(len(BPS)):\n",
    "    BPS[i] = BPS[i].drop(16)\n",
    "\n",
    "# ## Save files as pickle\n",
    "AZW_15.to_pickle(\"./Data/AZW_15.pkl\")\n",
    "\n",
    "with open('./Data/BPS.pkl', 'wb') as f:\n",
    "    pickle.dump(BPS, f)\n",
    "\n",
    "with open('./Data/Fname.pkl', 'wb') as f:\n",
    "    pickle.dump(Fname, f)\n",
    "\n",
    "with open('./Data/metabol14.pkl', 'wb') as f:\n",
    "    pickle.dump(metabol14, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a53763",
   "metadata": {},
   "source": [
    "## 2.2 Reload Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "190085da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will convert these to df depending on the building we choose\n",
    "# 2. Load 14 envimet bldgData (14 filtered buildings)\n",
    "with open('./Data/BPS.pkl', 'rb') as f:\n",
    "    envi14 = pickle.load(f)\n",
    "\n",
    "# 3. Load names of BPS files\n",
    "with open('./Data/Fname.pkl', 'rb') as f:\n",
    "    Fname = pickle.load(f)\n",
    "\n",
    "# 4. Load 14 campus metabolism building energy data\n",
    "with open('./Data/metabol14.pkl', 'rb') as f:\n",
    "    metabol14 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec8ad1",
   "metadata": {},
   "source": [
    "## 2.3 Choose building name to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be23924b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goldwater\n",
      "Best Hall\n",
      "COD North\n",
      "Bio Design Institute B\n",
      "University Club\n",
      "Engineering Research Ctr\n",
      "ISTB 2\n",
      "Interdisciplinary AB\n",
      "Health Services\n",
      "ISTB 5\n",
      "ISTB 1\n",
      "Lifescience A_B_D\n",
      "Bio Design Institute A\n",
      "ISTB 4\n",
      "Enter building name: ISTB 1\n"
     ]
    }
   ],
   "source": [
    "##Print Building Names ##\n",
    "for i in range(len(Fname)):\n",
    "    print(Fname[i])\n",
    "    \n",
    "bldname = input('Enter building name: ')\n",
    "\n",
    "for i in range(len(envi14)):\n",
    "    if bldname == Fname[i]:\n",
    "        # save \n",
    "        envi_bldg = envi14[i]\n",
    "\n",
    "if bldname not in Fname:\n",
    "    print(\"\\x1b[31m\\\"Please enter a valid name from the list above\\\"\\x1b[0m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef9bd09",
   "metadata": {},
   "source": [
    "## 2.4 Create Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0226c5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISTB 1\n"
     ]
    }
   ],
   "source": [
    "class building:\n",
    "    \n",
    "    def __init__(self, bldgname):\n",
    "        self.bldgname = bldgname\n",
    "    \n",
    "    def campusmetabolism(self):\n",
    "        for i in range(len(metabol14)):\n",
    "            if metabol14[i]['bldgname'][0] == bldname:\n",
    "                cmp = metabol14[i]\n",
    "            elif (metabol14[i]['bldgname'][0] == 'ISTB-5'):\n",
    "                cmp = metabol14[i]\n",
    "        return cmp\n",
    "    \n",
    "    def envimet(self):\n",
    "        env = envi_bldg[['Date', 'Time', 'AirTempInFrontOfAllFacades_MEAN', 'RelativeAirHumidityInFrontOfAllFacades_MEAN',\n",
    "                     'WindSpeedInFrontOfAllFacades_MEAN']]\n",
    "        \n",
    "        env = env.rename(columns = {'AirTempInFrontOfAllFacades_MEAN':'Air Temp',\n",
    "                                    'RelativeAirHumidityInFrontOfAllFacades_MEAN':'Rel Humid',\n",
    "                                    'WindSpeedInFrontOfAllFacades_MEAN':'Wind Speed'})\n",
    "        return env\n",
    "\n",
    "\n",
    "Bldg = building(bldname)\n",
    "metabol = Bldg.campusmetabolism() # campus metabolism\n",
    "envimet = Bldg.envimet()          # envimet\n",
    "print(bldname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e41497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv and convert to pkl, then read pkl below\n",
    "# AZW_15 = pd.read_csv(\"./Data/AZW_15.csv\")\n",
    "\n",
    "# DF for AZ Weather Data (15-min)\n",
    "weather_station = pd.read_pickle('./Data/AZW_15.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba767f",
   "metadata": {},
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51a64b4",
   "metadata": {},
   "source": [
    "## 3.1 Formatting Date and Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2db0cb1",
   "metadata": {},
   "source": [
    "### a) Envimet dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df05ddeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Time', 'Air Temp', 'Rel Humid', 'Wind Speed', 'Date_Time', 'Month']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biswas/.local/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 1. format time\n",
    "envimet['Time'] = envimet['Time'].str.replace('.',':')\n",
    "envimet['Time'] = envimet['Time'].str.replace('01','00')\n",
    "\n",
    "# convert to 24 hour format\n",
    "envimet['Time'] = pd.to_datetime(envimet['Time']).dt.strftime('%H:%M')\n",
    "\n",
    "# 2. format date (still in string)\n",
    "envimet['Date'] = pd.to_datetime(envimet['Date']).dt.strftime('%m/%d/%Y')\n",
    "\n",
    "# 3. combine date time column as string and set as index\n",
    "envimet['Date_Time'] = envimet['Date'] + ' ' + envimet['Time']\n",
    "\n",
    "# 4. Get string type for month and time\n",
    "envimet['Month'] = envimet['Date_Time'].str[0:2]\n",
    "envimet['Time'] = envimet['Time'].str.replace(':','')\n",
    "\n",
    "# 5. Rearrange columns\n",
    "print(list(envimet.columns))\n",
    "envimet = envimet[['Date_Time','Month','Time', 'Air Temp', 'Rel Humid' ]]\n",
    "\n",
    "envimet = envimet.set_index('Date_Time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c1610fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5. Get numeric for month hour and minute\n",
    "# microclimate.Date_Time = pd.to_datetime(microclimate.Date_Time)\n",
    "# microclimate['Month_num'] = microclimate.Date_Time.dt.month\n",
    "# microclimate['Hour_num'] = microclimate.Date_Time.dt.hour\n",
    "# microclimate['Minute_num'] = microclimate.Date_Time.dt.minute\n",
    "# microclimate.Date_Time = pd.to_datetime(microclimate.Date_Time).dt.strftime('%m/%d/%Y %H:%M')\n",
    "\n",
    "# # 6. Rearrange columns\n",
    "# print(list(microclimate.columns))\n",
    "# microclimate = microclimate[['Date_Time','Month','Time','Month_num', 'Hour_num', 'Minute_num', 'Air Temp', 'Rel Humid' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960b89e0",
   "metadata": {},
   "source": [
    "### b) Weather Station dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e7afa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get string type for month and time\n",
    "weather_station['Month'] = weather_station['Date_Time'].str[0:2]\n",
    "weather_station['Time'] = weather_station['Date_Time'].str[11:]\n",
    "weather_station['Time'] = weather_station['Time'].str.replace(':','')\n",
    "\n",
    "# 2. Get numeric for month hour and minute\n",
    "weather_station.Date_Time = pd.to_datetime(weather_station.Date_Time)\n",
    "weather_station['Month_num'] = weather_station.Date_Time.dt.month\n",
    "weather_station['Hour_num'] = weather_station.Date_Time.dt.hour\n",
    "weather_station['Minute_num'] = weather_station.Date_Time.dt.minute\n",
    "weather_station.Date_Time = pd.to_datetime(weather_station.Date_Time).dt.strftime('%m/%d/%Y %H:%M')\n",
    "\n",
    "# 3. set date time as index\n",
    "weather_station = weather_station.set_index('Date_Time') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096d5fe6",
   "metadata": {},
   "source": [
    "### c) Building energy dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c938e408",
   "metadata": {},
   "outputs": [],
   "source": [
    "metabol.tstamp = pd.to_datetime(metabol.tstamp).dt.strftime('%m/%d/%Y %H:%M')\n",
    "\n",
    "# remove unwanted columns\n",
    "metabol = metabol[['tstamp','KW', 'CHWTON']]\n",
    "\n",
    "# set date time as index\n",
    "metabol = metabol.set_index('tstamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e54f14",
   "metadata": {},
   "source": [
    "## 3.2 Append Energy Consumption to Weather Station data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e876d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station =  pd.concat([metabol, weather_station], axis = 1, join = \"inner\")\n",
    "\n",
    "# rearrange column\n",
    "weather_station = weather_station[['Month','Time','Month_num', 'Hour_num', 'Minute_num', 'Air Temp', 'Rel Humid', 'KW','CHWTON' ]]\n",
    "\n",
    "# weather_station.to_csv('./Data/weather_st_numstr') # save data with string and numeric date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ec4a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station.to_csv('./Data/weather_st.csv') # save data with string and numeric date format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "023b6ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-14 08:38:31.547162: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/biswas/testing/devel/lib:/home/biswas/catkin_ws/devel/lib:/opt/ros/melodic/lib\n",
      "2021-09-14 08:38:31.547193: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34620, 9)\n",
      "(34620, 2)\n",
      "(34620, 2)\n",
      "(34620, 1)\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-14 08:38:32.421275: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2021-09-14 08:38:32.457281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-14 08:38:32.458154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:03:00.0 name: GeForce MX130 computeCapability: 5.0\n",
      "coreClock: 1.189GHz coreCount: 3 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 37.33GiB/s\n",
      "2021-09-14 08:38:32.458361: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/biswas/testing/devel/lib:/home/biswas/catkin_ws/devel/lib:/opt/ros/melodic/lib\n",
      "2021-09-14 08:38:32.458534: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/biswas/testing/devel/lib:/home/biswas/catkin_ws/devel/lib:/opt/ros/melodic/lib\n",
      "2021-09-14 08:38:32.458669: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/biswas/testing/devel/lib:/home/biswas/catkin_ws/devel/lib:/opt/ros/melodic/lib\n",
      "2021-09-14 08:38:32.458822: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/biswas/testing/devel/lib:/home/biswas/catkin_ws/devel/lib:/opt/ros/melodic/lib\n",
      "2021-09-14 08:38:32.458956: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/biswas/testing/devel/lib:/home/biswas/catkin_ws/devel/lib:/opt/ros/melodic/lib\n",
      "2021-09-14 08:38:32.459083: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/biswas/testing/devel/lib:/home/biswas/catkin_ws/devel/lib:/opt/ros/melodic/lib\n",
      "2021-09-14 08:38:32.459209: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/biswas/testing/devel/lib:/home/biswas/catkin_ws/devel/lib:/opt/ros/melodic/lib\n",
      "2021-09-14 08:38:32.459225: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-09-14 08:38:32.459663: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-14 08:38:32.466872: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2099940000 Hz\n",
      "2021-09-14 08:38:32.467272: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xa114cf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-09-14 08:38:32.467303: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-09-14 08:38:32.468620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-14 08:38:32.468639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 0s 1ms/step - loss: 0.6632 - mse: 0.6632 - mae: 0.6883 - val_loss: 0.3806 - val_mse: 0.3806 - val_mae: 0.4913\n",
      "Epoch 2/200\n",
      "174/174 [==============================] - 0s 606us/step - loss: 0.2998 - mse: 0.2998 - mae: 0.4307 - val_loss: 0.2523 - val_mse: 0.2523 - val_mae: 0.3977\n",
      "Epoch 3/200\n",
      "174/174 [==============================] - 0s 593us/step - loss: 0.2168 - mse: 0.2168 - mae: 0.3669 - val_loss: 0.1899 - val_mse: 0.1899 - val_mae: 0.3453\n",
      "Epoch 4/200\n",
      "174/174 [==============================] - 0s 627us/step - loss: 0.1695 - mse: 0.1695 - mae: 0.3251 - val_loss: 0.1513 - val_mse: 0.1513 - val_mae: 0.3099\n",
      "Epoch 5/200\n",
      "174/174 [==============================] - 0s 671us/step - loss: 0.1388 - mse: 0.1388 - mae: 0.2959 - val_loss: 0.1263 - val_mse: 0.1263 - val_mae: 0.2838\n",
      "Epoch 6/200\n",
      "174/174 [==============================] - 0s 772us/step - loss: 0.1197 - mse: 0.1197 - mae: 0.2751 - val_loss: 0.1104 - val_mse: 0.1104 - val_mae: 0.2650\n",
      "Epoch 7/200\n",
      "174/174 [==============================] - 0s 610us/step - loss: 0.1077 - mse: 0.1077 - mae: 0.2605 - val_loss: 0.1007 - val_mse: 0.1007 - val_mae: 0.2527\n",
      "Epoch 8/200\n",
      "174/174 [==============================] - 0s 603us/step - loss: 0.1004 - mse: 0.1004 - mae: 0.2507 - val_loss: 0.0949 - val_mse: 0.0949 - val_mae: 0.2430\n",
      "Epoch 9/200\n",
      "174/174 [==============================] - 0s 678us/step - loss: 0.0958 - mse: 0.0958 - mae: 0.2430 - val_loss: 0.0918 - val_mse: 0.0918 - val_mae: 0.2383\n",
      "Epoch 10/200\n",
      "174/174 [==============================] - 0s 601us/step - loss: 0.0932 - mse: 0.0932 - mae: 0.2386 - val_loss: 0.0892 - val_mse: 0.0892 - val_mae: 0.2324\n",
      "Epoch 11/200\n",
      "174/174 [==============================] - 0s 784us/step - loss: 0.0916 - mse: 0.0916 - mae: 0.2351 - val_loss: 0.0881 - val_mse: 0.0881 - val_mae: 0.2309\n",
      "Epoch 12/200\n",
      "174/174 [==============================] - 0s 632us/step - loss: 0.0905 - mse: 0.0905 - mae: 0.2333 - val_loss: 0.0877 - val_mse: 0.0877 - val_mae: 0.2308\n",
      "Epoch 13/200\n",
      "174/174 [==============================] - 0s 614us/step - loss: 0.0897 - mse: 0.0897 - mae: 0.2315 - val_loss: 0.0870 - val_mse: 0.0870 - val_mae: 0.2281\n",
      "Epoch 14/200\n",
      "174/174 [==============================] - 0s 652us/step - loss: 0.0894 - mse: 0.0894 - mae: 0.2309 - val_loss: 0.0866 - val_mse: 0.0866 - val_mae: 0.2276\n",
      "Epoch 15/200\n",
      "174/174 [==============================] - 0s 635us/step - loss: 0.0891 - mse: 0.0891 - mae: 0.2303 - val_loss: 0.0867 - val_mse: 0.0867 - val_mae: 0.2283\n",
      "Epoch 16/200\n",
      "174/174 [==============================] - 0s 639us/step - loss: 0.0890 - mse: 0.0890 - mae: 0.2299 - val_loss: 0.0862 - val_mse: 0.0862 - val_mae: 0.2275\n",
      "Epoch 17/200\n",
      "174/174 [==============================] - 0s 613us/step - loss: 0.0887 - mse: 0.0887 - mae: 0.2291 - val_loss: 0.0866 - val_mse: 0.0866 - val_mae: 0.2287\n",
      "Epoch 18/200\n",
      "174/174 [==============================] - 0s 616us/step - loss: 0.0888 - mse: 0.0888 - mae: 0.2298 - val_loss: 0.0861 - val_mse: 0.0861 - val_mae: 0.2249\n",
      "Epoch 19/200\n",
      "174/174 [==============================] - 0s 600us/step - loss: 0.0885 - mse: 0.0885 - mae: 0.2288 - val_loss: 0.0858 - val_mse: 0.0858 - val_mae: 0.2261\n",
      "Epoch 20/200\n",
      "174/174 [==============================] - 0s 588us/step - loss: 0.0885 - mse: 0.0885 - mae: 0.2287 - val_loss: 0.0861 - val_mse: 0.0861 - val_mae: 0.2276\n",
      "Epoch 21/200\n",
      "174/174 [==============================] - 0s 606us/step - loss: 0.0885 - mse: 0.0885 - mae: 0.2288 - val_loss: 0.0860 - val_mse: 0.0860 - val_mae: 0.2268\n",
      "Epoch 22/200\n",
      "174/174 [==============================] - 0s 616us/step - loss: 0.0885 - mse: 0.0885 - mae: 0.2287 - val_loss: 0.0857 - val_mse: 0.0857 - val_mae: 0.2251\n",
      "Epoch 23/200\n",
      "174/174 [==============================] - 0s 623us/step - loss: 0.0885 - mse: 0.0885 - mae: 0.2288 - val_loss: 0.0862 - val_mse: 0.0862 - val_mae: 0.2249\n",
      "Epoch 24/200\n",
      "174/174 [==============================] - 0s 608us/step - loss: 0.0884 - mse: 0.0884 - mae: 0.2278 - val_loss: 0.0869 - val_mse: 0.0869 - val_mae: 0.2301\n",
      "Epoch 25/200\n",
      "174/174 [==============================] - 0s 607us/step - loss: 0.0882 - mse: 0.0882 - mae: 0.2284 - val_loss: 0.0859 - val_mse: 0.0859 - val_mae: 0.2266\n",
      "Epoch 26/200\n",
      "174/174 [==============================] - 0s 611us/step - loss: 0.0883 - mse: 0.0883 - mae: 0.2287 - val_loss: 0.0856 - val_mse: 0.0856 - val_mae: 0.2253\n",
      "Epoch 27/200\n",
      "174/174 [==============================] - 0s 609us/step - loss: 0.0881 - mse: 0.0881 - mae: 0.2277 - val_loss: 0.0859 - val_mse: 0.0859 - val_mae: 0.2270\n",
      "Epoch 28/200\n",
      "174/174 [==============================] - 0s 590us/step - loss: 0.0881 - mse: 0.0881 - mae: 0.2283 - val_loss: 0.0859 - val_mse: 0.0859 - val_mae: 0.2253\n",
      "Epoch 29/200\n",
      "174/174 [==============================] - 0s 591us/step - loss: 0.0880 - mse: 0.0880 - mae: 0.2278 - val_loss: 0.0856 - val_mse: 0.0856 - val_mae: 0.2255\n",
      "Epoch 30/200\n",
      "174/174 [==============================] - 0s 594us/step - loss: 0.0879 - mse: 0.0879 - mae: 0.2276 - val_loss: 0.0854 - val_mse: 0.0854 - val_mae: 0.2249\n",
      "Epoch 31/200\n",
      "174/174 [==============================] - 0s 583us/step - loss: 0.0881 - mse: 0.0881 - mae: 0.2273 - val_loss: 0.0855 - val_mse: 0.0855 - val_mae: 0.2246\n",
      "Epoch 32/200\n",
      "174/174 [==============================] - 0s 606us/step - loss: 0.0880 - mse: 0.0880 - mae: 0.2278 - val_loss: 0.0868 - val_mse: 0.0868 - val_mae: 0.2248\n",
      "Epoch 33/200\n",
      "174/174 [==============================] - 0s 590us/step - loss: 0.0880 - mse: 0.0880 - mae: 0.2270 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2235\n",
      "Epoch 34/200\n",
      "174/174 [==============================] - 0s 599us/step - loss: 0.0878 - mse: 0.0878 - mae: 0.2265 - val_loss: 0.0858 - val_mse: 0.0858 - val_mae: 0.2251\n",
      "Epoch 35/200\n",
      "174/174 [==============================] - 0s 583us/step - loss: 0.0878 - mse: 0.0878 - mae: 0.2269 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2243\n",
      "Epoch 36/200\n",
      "174/174 [==============================] - 0s 581us/step - loss: 0.0878 - mse: 0.0878 - mae: 0.2269 - val_loss: 0.0865 - val_mse: 0.0865 - val_mae: 0.2271\n",
      "Epoch 37/200\n",
      "174/174 [==============================] - 0s 586us/step - loss: 0.0880 - mse: 0.0880 - mae: 0.2271 - val_loss: 0.0857 - val_mse: 0.0857 - val_mae: 0.2259\n",
      "Epoch 38/200\n",
      "174/174 [==============================] - 0s 832us/step - loss: 0.0879 - mse: 0.0879 - mae: 0.2273 - val_loss: 0.0867 - val_mse: 0.0867 - val_mae: 0.2276\n",
      "Epoch 39/200\n",
      "174/174 [==============================] - 0s 625us/step - loss: 0.0879 - mse: 0.0879 - mae: 0.2269 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2244\n",
      "Epoch 40/200\n",
      "174/174 [==============================] - 0s 598us/step - loss: 0.0878 - mse: 0.0878 - mae: 0.2268 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2252\n",
      "Epoch 41/200\n",
      "174/174 [==============================] - 0s 657us/step - loss: 0.0878 - mse: 0.0878 - mae: 0.2267 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2241\n",
      "Epoch 42/200\n",
      "174/174 [==============================] - 0s 600us/step - loss: 0.0877 - mse: 0.0877 - mae: 0.2263 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2247\n",
      "Epoch 43/200\n",
      "174/174 [==============================] - 0s 593us/step - loss: 0.0878 - mse: 0.0878 - mae: 0.2268 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2256\n",
      "Epoch 44/200\n",
      "174/174 [==============================] - 0s 585us/step - loss: 0.0879 - mse: 0.0879 - mae: 0.2269 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2236\n",
      "Epoch 45/200\n",
      "174/174 [==============================] - 0s 580us/step - loss: 0.0878 - mse: 0.0878 - mae: 0.2267 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2245\n",
      "Epoch 46/200\n",
      "174/174 [==============================] - 0s 632us/step - loss: 0.0878 - mse: 0.0878 - mae: 0.2266 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2241\n",
      "Epoch 47/200\n",
      "174/174 [==============================] - 0s 633us/step - loss: 0.0879 - mse: 0.0879 - mae: 0.2267 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2240\n",
      "Epoch 48/200\n",
      "174/174 [==============================] - 0s 697us/step - loss: 0.0877 - mse: 0.0877 - mae: 0.2262 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2241\n",
      "Epoch 49/200\n",
      "174/174 [==============================] - 0s 637us/step - loss: 0.0877 - mse: 0.0877 - mae: 0.2267 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "174/174 [==============================] - 0s 631us/step - loss: 0.0879 - mse: 0.0879 - mae: 0.2263 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2250\n",
      "Epoch 51/200\n",
      "174/174 [==============================] - 0s 649us/step - loss: 0.0878 - mse: 0.0878 - mae: 0.2268 - val_loss: 0.0855 - val_mse: 0.0855 - val_mae: 0.2265\n",
      "Epoch 52/200\n",
      "174/174 [==============================] - 0s 600us/step - loss: 0.0877 - mse: 0.0877 - mae: 0.2268 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2255\n",
      "Epoch 53/200\n",
      "174/174 [==============================] - 0s 598us/step - loss: 0.0878 - mse: 0.0878 - mae: 0.2266 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2243\n",
      "Epoch 54/200\n",
      "174/174 [==============================] - 0s 638us/step - loss: 0.0878 - mse: 0.0878 - mae: 0.2264 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2242\n",
      "Epoch 55/200\n",
      "174/174 [==============================] - 0s 598us/step - loss: 0.0877 - mse: 0.0877 - mae: 0.2262 - val_loss: 0.0856 - val_mse: 0.0856 - val_mae: 0.2252\n",
      "Epoch 56/200\n",
      "174/174 [==============================] - 0s 666us/step - loss: 0.0878 - mse: 0.0878 - mae: 0.2267 - val_loss: 0.0856 - val_mse: 0.0856 - val_mae: 0.2244\n",
      "Epoch 57/200\n",
      "174/174 [==============================] - 0s 605us/step - loss: 0.0877 - mse: 0.0877 - mae: 0.2267 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2241\n",
      "Epoch 58/200\n",
      "174/174 [==============================] - 0s 598us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2262 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2231\n",
      "Epoch 59/200\n",
      "174/174 [==============================] - 0s 603us/step - loss: 0.0877 - mse: 0.0877 - mae: 0.2261 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2233\n",
      "Epoch 60/200\n",
      "174/174 [==============================] - 0s 659us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2264 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2256\n",
      "Epoch 61/200\n",
      "174/174 [==============================] - 0s 625us/step - loss: 0.0878 - mse: 0.0878 - mae: 0.2264 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2252\n",
      "Epoch 62/200\n",
      "174/174 [==============================] - 0s 608us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2265 - val_loss: 0.0863 - val_mse: 0.0863 - val_mae: 0.2262\n",
      "Epoch 63/200\n",
      "174/174 [==============================] - 0s 619us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2260 - val_loss: 0.0855 - val_mse: 0.0855 - val_mae: 0.2261\n",
      "Epoch 64/200\n",
      "174/174 [==============================] - 0s 611us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2263 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2256\n",
      "Epoch 65/200\n",
      "174/174 [==============================] - 0s 594us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2266 - val_loss: 0.0861 - val_mse: 0.0861 - val_mae: 0.2264\n",
      "Epoch 66/200\n",
      "174/174 [==============================] - 0s 616us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2262 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2248\n",
      "Epoch 67/200\n",
      "174/174 [==============================] - 0s 614us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2262 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2248\n",
      "Epoch 68/200\n",
      "174/174 [==============================] - 0s 647us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2264 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2240\n",
      "Epoch 69/200\n",
      "174/174 [==============================] - 0s 616us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2262 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2251\n",
      "Epoch 70/200\n",
      "174/174 [==============================] - 0s 605us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2264 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2248\n",
      "Epoch 71/200\n",
      "174/174 [==============================] - 0s 655us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2262 - val_loss: 0.0855 - val_mse: 0.0855 - val_mae: 0.2250\n",
      "Epoch 72/200\n",
      "174/174 [==============================] - 0s 606us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2263 - val_loss: 0.0857 - val_mse: 0.0857 - val_mae: 0.2242\n",
      "Epoch 73/200\n",
      "174/174 [==============================] - 0s 613us/step - loss: 0.0877 - mse: 0.0877 - mae: 0.2263 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2251\n",
      "Epoch 74/200\n",
      "174/174 [==============================] - 0s 592us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2265 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2247\n",
      "Epoch 75/200\n",
      "174/174 [==============================] - 0s 627us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2260 - val_loss: 0.0855 - val_mse: 0.0855 - val_mae: 0.2255\n",
      "Epoch 76/200\n",
      "174/174 [==============================] - 0s 607us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2265 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2240\n",
      "Epoch 77/200\n",
      "174/174 [==============================] - 0s 594us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2262 - val_loss: 0.0856 - val_mse: 0.0856 - val_mae: 0.2259\n",
      "Epoch 78/200\n",
      "174/174 [==============================] - 0s 601us/step - loss: 0.0877 - mse: 0.0877 - mae: 0.2264 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2227\n",
      "Epoch 79/200\n",
      "174/174 [==============================] - 0s 631us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2261 - val_loss: 0.0855 - val_mse: 0.0855 - val_mae: 0.2255\n",
      "Epoch 80/200\n",
      "174/174 [==============================] - 0s 626us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2260 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2250\n",
      "Epoch 81/200\n",
      "174/174 [==============================] - 0s 640us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2263 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2244\n",
      "Epoch 82/200\n",
      "174/174 [==============================] - 0s 627us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2262 - val_loss: 0.0858 - val_mse: 0.0858 - val_mae: 0.2254\n",
      "Epoch 83/200\n",
      "174/174 [==============================] - 0s 611us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2262 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2234\n",
      "Epoch 84/200\n",
      "174/174 [==============================] - 0s 594us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2263 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2232\n",
      "Epoch 85/200\n",
      "174/174 [==============================] - 0s 619us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2260 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2236\n",
      "Epoch 86/200\n",
      "174/174 [==============================] - 0s 616us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2261 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2256\n",
      "Epoch 87/200\n",
      "174/174 [==============================] - 0s 608us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2262 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2224\n",
      "Epoch 88/200\n",
      "174/174 [==============================] - 0s 602us/step - loss: 0.0877 - mse: 0.0877 - mae: 0.2261 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2257\n",
      "Epoch 89/200\n",
      "174/174 [==============================] - 0s 579us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2265 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2230\n",
      "Epoch 90/200\n",
      "174/174 [==============================] - 0s 603us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2260 - val_loss: 0.0857 - val_mse: 0.0857 - val_mae: 0.2263\n",
      "Epoch 91/200\n",
      "174/174 [==============================] - 0s 590us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2262 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2249\n",
      "Epoch 92/200\n",
      "174/174 [==============================] - 0s 603us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2263 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2247\n",
      "Epoch 93/200\n",
      "174/174 [==============================] - 0s 601us/step - loss: 0.0878 - mse: 0.0878 - mae: 0.2265 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2232\n",
      "Epoch 94/200\n",
      "174/174 [==============================] - 0s 610us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2259 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2248\n",
      "Epoch 95/200\n",
      "174/174 [==============================] - 0s 606us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2260 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2244\n",
      "Epoch 96/200\n",
      "174/174 [==============================] - 0s 616us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2261 - val_loss: 0.0854 - val_mse: 0.0854 - val_mae: 0.2247\n",
      "Epoch 97/200\n",
      "174/174 [==============================] - 0s 623us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2263 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2236\n",
      "Epoch 98/200\n",
      "174/174 [==============================] - 0s 617us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2263 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200\n",
      "174/174 [==============================] - 0s 633us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2261 - val_loss: 0.0860 - val_mse: 0.0860 - val_mae: 0.2258\n",
      "Epoch 100/200\n",
      "174/174 [==============================] - 0s 643us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2260 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2251\n",
      "Epoch 101/200\n",
      "174/174 [==============================] - 0s 609us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2257 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2262\n",
      "Epoch 102/200\n",
      "174/174 [==============================] - 0s 607us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2260 - val_loss: 0.0855 - val_mse: 0.0855 - val_mae: 0.2256\n",
      "Epoch 103/200\n",
      "174/174 [==============================] - 0s 603us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2263 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2241\n",
      "Epoch 104/200\n",
      "174/174 [==============================] - 0s 597us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2265 - val_loss: 0.0854 - val_mse: 0.0854 - val_mae: 0.2244\n",
      "Epoch 105/200\n",
      "174/174 [==============================] - 0s 605us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2261 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2238\n",
      "Epoch 106/200\n",
      "174/174 [==============================] - 0s 588us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2263 - val_loss: 0.0854 - val_mse: 0.0854 - val_mae: 0.2236\n",
      "Epoch 107/200\n",
      "174/174 [==============================] - 0s 609us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2260 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2234\n",
      "Epoch 108/200\n",
      "174/174 [==============================] - 0s 620us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2258 - val_loss: 0.0859 - val_mse: 0.0859 - val_mae: 0.2272\n",
      "Epoch 109/200\n",
      "174/174 [==============================] - 0s 592us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2258 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2250\n",
      "Epoch 110/200\n",
      "174/174 [==============================] - 0s 612us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2261 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2241\n",
      "Epoch 111/200\n",
      "174/174 [==============================] - 0s 603us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2263 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2235\n",
      "Epoch 112/200\n",
      "174/174 [==============================] - 0s 602us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2260 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2249\n",
      "Epoch 113/200\n",
      "174/174 [==============================] - 0s 606us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2260 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2230\n",
      "Epoch 114/200\n",
      "174/174 [==============================] - 0s 588us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2258 - val_loss: 0.0858 - val_mse: 0.0858 - val_mae: 0.2267\n",
      "Epoch 115/200\n",
      "174/174 [==============================] - 0s 587us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2264 - val_loss: 0.0859 - val_mse: 0.0859 - val_mae: 0.2266\n",
      "Epoch 116/200\n",
      "174/174 [==============================] - 0s 591us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2261 - val_loss: 0.0863 - val_mse: 0.0863 - val_mae: 0.2261\n",
      "Epoch 117/200\n",
      "174/174 [==============================] - 0s 589us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2259 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2223\n",
      "Epoch 118/200\n",
      "174/174 [==============================] - 0s 629us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2258 - val_loss: 0.0857 - val_mse: 0.0857 - val_mae: 0.2261\n",
      "Epoch 119/200\n",
      "174/174 [==============================] - 0s 589us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2262 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2231\n",
      "Epoch 120/200\n",
      "174/174 [==============================] - 0s 585us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2260 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2244\n",
      "Epoch 121/200\n",
      "174/174 [==============================] - 0s 601us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2264 - val_loss: 0.0854 - val_mse: 0.0854 - val_mae: 0.2250\n",
      "Epoch 122/200\n",
      "174/174 [==============================] - 0s 614us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2261 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2239\n",
      "Epoch 123/200\n",
      "174/174 [==============================] - 0s 592us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2264 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2231\n",
      "Epoch 124/200\n",
      "174/174 [==============================] - 0s 600us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2262 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2247\n",
      "Epoch 125/200\n",
      "174/174 [==============================] - 0s 609us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2259 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2253\n",
      "Epoch 126/200\n",
      "174/174 [==============================] - 0s 606us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2262 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2239\n",
      "Epoch 127/200\n",
      "174/174 [==============================] - 0s 589us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2259 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2230\n",
      "Epoch 128/200\n",
      "174/174 [==============================] - 0s 611us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2259 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2240\n",
      "Epoch 129/200\n",
      "174/174 [==============================] - 0s 593us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2261 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2226\n",
      "Epoch 130/200\n",
      "174/174 [==============================] - 0s 607us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2257 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2244\n",
      "Epoch 131/200\n",
      "174/174 [==============================] - 0s 579us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2258 - val_loss: 0.0864 - val_mse: 0.0864 - val_mae: 0.2259\n",
      "Epoch 132/200\n",
      "174/174 [==============================] - 0s 612us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2263 - val_loss: 0.0848 - val_mse: 0.0848 - val_mae: 0.2222\n",
      "Epoch 133/200\n",
      "174/174 [==============================] - 0s 594us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2255 - val_loss: 0.0855 - val_mse: 0.0855 - val_mae: 0.2254\n",
      "Epoch 134/200\n",
      "174/174 [==============================] - 0s 587us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2261 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2225\n",
      "Epoch 135/200\n",
      "174/174 [==============================] - 0s 595us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2256 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2246\n",
      "Epoch 136/200\n",
      "174/174 [==============================] - 0s 604us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2259 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2235\n",
      "Epoch 137/200\n",
      "174/174 [==============================] - 0s 606us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2258 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2255\n",
      "Epoch 138/200\n",
      "174/174 [==============================] - 0s 587us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2260 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2236\n",
      "Epoch 139/200\n",
      "174/174 [==============================] - 0s 630us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2263 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2229\n",
      "Epoch 140/200\n",
      "174/174 [==============================] - 0s 601us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2259 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2249\n",
      "Epoch 141/200\n",
      "174/174 [==============================] - 0s 591us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2260 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2247\n",
      "Epoch 142/200\n",
      "174/174 [==============================] - 0s 602us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2262 - val_loss: 0.0858 - val_mse: 0.0858 - val_mae: 0.2254\n",
      "Epoch 143/200\n",
      "174/174 [==============================] - 0s 601us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2259 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2235\n",
      "Epoch 144/200\n",
      "174/174 [==============================] - 0s 621us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2259 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2241\n",
      "Epoch 145/200\n",
      "174/174 [==============================] - 0s 573us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2263 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2246\n",
      "Epoch 146/200\n",
      "174/174 [==============================] - 0s 610us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2261 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2233\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 0s 611us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2258 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2249\n",
      "Epoch 148/200\n",
      "174/174 [==============================] - 0s 585us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2259 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2229\n",
      "Epoch 149/200\n",
      "174/174 [==============================] - 0s 596us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2258 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2247\n",
      "Epoch 150/200\n",
      "174/174 [==============================] - 0s 576us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2260 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2245\n",
      "Epoch 151/200\n",
      "174/174 [==============================] - 0s 596us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2261 - val_loss: 0.0848 - val_mse: 0.0848 - val_mae: 0.2225\n",
      "Epoch 152/200\n",
      "174/174 [==============================] - 0s 623us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2255 - val_loss: 0.0855 - val_mse: 0.0855 - val_mae: 0.2251\n",
      "Epoch 153/200\n",
      "174/174 [==============================] - 0s 608us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2261 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2240\n",
      "Epoch 154/200\n",
      "174/174 [==============================] - 0s 599us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2261 - val_loss: 0.0859 - val_mse: 0.0859 - val_mae: 0.2240\n",
      "Epoch 155/200\n",
      "174/174 [==============================] - 0s 576us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2261 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2252\n",
      "Epoch 156/200\n",
      "174/174 [==============================] - 0s 603us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2259 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2244\n",
      "Epoch 157/200\n",
      "174/174 [==============================] - 0s 596us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2263 - val_loss: 0.0861 - val_mse: 0.0861 - val_mae: 0.2257\n",
      "Epoch 158/200\n",
      "174/174 [==============================] - 0s 610us/step - loss: 0.0876 - mse: 0.0876 - mae: 0.2260 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2240\n",
      "Epoch 159/200\n",
      "174/174 [==============================] - 0s 590us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2260 - val_loss: 0.0848 - val_mse: 0.0848 - val_mae: 0.2220\n",
      "Epoch 160/200\n",
      "174/174 [==============================] - 0s 595us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2257 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2236\n",
      "Epoch 161/200\n",
      "174/174 [==============================] - 0s 591us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2261 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2229\n",
      "Epoch 162/200\n",
      "174/174 [==============================] - 0s 593us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2258 - val_loss: 0.0848 - val_mse: 0.0848 - val_mae: 0.2231\n",
      "Epoch 163/200\n",
      "174/174 [==============================] - 0s 615us/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2255 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2248\n",
      "Epoch 164/200\n",
      "174/174 [==============================] - 0s 592us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2260 - val_loss: 0.0848 - val_mse: 0.0848 - val_mae: 0.2228\n",
      "Epoch 165/200\n",
      "174/174 [==============================] - 0s 591us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2257 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2241\n",
      "Epoch 166/200\n",
      "174/174 [==============================] - 0s 597us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2261 - val_loss: 0.0856 - val_mse: 0.0856 - val_mae: 0.2249\n",
      "Epoch 167/200\n",
      "174/174 [==============================] - 0s 596us/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2256 - val_loss: 0.0857 - val_mse: 0.0857 - val_mae: 0.2239\n",
      "Epoch 168/200\n",
      "174/174 [==============================] - 0s 598us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2261 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2233\n",
      "Epoch 169/200\n",
      "174/174 [==============================] - 0s 579us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2255 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2248\n",
      "Epoch 170/200\n",
      "174/174 [==============================] - 0s 594us/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2257 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2250\n",
      "Epoch 171/200\n",
      "174/174 [==============================] - 0s 594us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2262 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2250\n",
      "Epoch 172/200\n",
      "174/174 [==============================] - 0s 639us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2263 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2232\n",
      "Epoch 173/200\n",
      "174/174 [==============================] - 0s 607us/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2255 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2241\n",
      "Epoch 174/200\n",
      "174/174 [==============================] - 0s 603us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2259 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2235\n",
      "Epoch 175/200\n",
      "174/174 [==============================] - 0s 614us/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2257 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2238\n",
      "Epoch 176/200\n",
      "174/174 [==============================] - 0s 599us/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2255 - val_loss: 0.0865 - val_mse: 0.0865 - val_mae: 0.2260\n",
      "Epoch 177/200\n",
      "174/174 [==============================] - 0s 601us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2258 - val_loss: 0.0856 - val_mse: 0.0856 - val_mae: 0.2257\n",
      "Epoch 178/200\n",
      "174/174 [==============================] - 0s 585us/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2254 - val_loss: 0.0856 - val_mse: 0.0856 - val_mae: 0.2263\n",
      "Epoch 179/200\n",
      "174/174 [==============================] - 0s 606us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2260 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2231\n",
      "Epoch 180/200\n",
      "174/174 [==============================] - 0s 617us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2258 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2239\n",
      "Epoch 181/200\n",
      "174/174 [==============================] - 0s 595us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2258 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2254\n",
      "Epoch 182/200\n",
      "174/174 [==============================] - 0s 628us/step - loss: 0.0875 - mse: 0.0875 - mae: 0.2261 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2250\n",
      "Epoch 183/200\n",
      "174/174 [==============================] - 0s 624us/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2260 - val_loss: 0.0855 - val_mse: 0.0855 - val_mae: 0.2253\n",
      "Epoch 184/200\n",
      "174/174 [==============================] - 0s 579us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2259 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2224\n",
      "Epoch 185/200\n",
      "174/174 [==============================] - 0s 607us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2257 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2235\n",
      "Epoch 186/200\n",
      "174/174 [==============================] - 0s 592us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2257 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2243\n",
      "Epoch 187/200\n",
      "174/174 [==============================] - 0s 601us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2258 - val_loss: 0.0853 - val_mse: 0.0853 - val_mae: 0.2244\n",
      "Epoch 188/200\n",
      "174/174 [==============================] - 0s 590us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2256 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2235\n",
      "Epoch 189/200\n",
      "174/174 [==============================] - 0s 592us/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2257 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2244\n",
      "Epoch 190/200\n",
      "174/174 [==============================] - 0s 590us/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2255 - val_loss: 0.0855 - val_mse: 0.0855 - val_mae: 0.2269\n",
      "Epoch 191/200\n",
      "174/174 [==============================] - 0s 601us/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2258 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2241\n",
      "Epoch 192/200\n",
      "174/174 [==============================] - 0s 601us/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2255 - val_loss: 0.0858 - val_mse: 0.0858 - val_mae: 0.2267\n",
      "Epoch 193/200\n",
      "174/174 [==============================] - 0s 610us/step - loss: 0.0874 - mse: 0.0874 - mae: 0.2260 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2236\n",
      "Epoch 194/200\n",
      "174/174 [==============================] - 0s 604us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2257 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2234\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 0s 583us/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2256 - val_loss: 0.0859 - val_mse: 0.0859 - val_mae: 0.2255\n",
      "Epoch 196/200\n",
      "174/174 [==============================] - 0s 593us/step - loss: 0.0872 - mse: 0.0872 - mae: 0.2256 - val_loss: 0.0852 - val_mse: 0.0852 - val_mae: 0.2248\n",
      "Epoch 197/200\n",
      "174/174 [==============================] - 0s 578us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2258 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2225\n",
      "Epoch 198/200\n",
      "174/174 [==============================] - 0s 603us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2257 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2236\n",
      "Epoch 199/200\n",
      "174/174 [==============================] - 0s 607us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2261 - val_loss: 0.0849 - val_mse: 0.0849 - val_mae: 0.2229\n",
      "Epoch 200/200\n",
      "174/174 [==============================] - 0s 600us/step - loss: 0.0873 - mse: 0.0873 - mae: 0.2257 - val_loss: 0.0851 - val_mse: 0.0851 - val_mae: 0.2247\n"
     ]
    }
   ],
   "source": [
    "#using single layer ANN. Model Parameters: hidden layer- 10 neurons, output layer- 1 neuron\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "print(weather_station.shape)\n",
    "Y = weather_station['CHWTON']\n",
    "X = weather_station.drop(labels = ['Month','Time','Month_num', 'Hour_num', 'Minute_num', 'KW','CHWTON'], axis = 1)\n",
    "\n",
    "\n",
    "#keep only temperature and relative humidity parameter in your dataset\n",
    "#normalize your data to get values between 0 and 1\n",
    "# X= X.values.reshape(-1, 2)\n",
    "Y= Y.values.reshape(-1, 1)\n",
    "print(X.shape)\n",
    "# create scaler\n",
    "scaler1 = StandardScaler()\n",
    "X_scaled = scaler1.fit_transform(X)\n",
    "print(X_scaled.shape)\n",
    "# #do for output variables\n",
    "scaler2 = StandardScaler()\n",
    "Y_scaled = scaler2.fit_transform(Y)\n",
    "X_scaled = np.asarray(X_scaled).astype('float32')\n",
    "Y_scaled = np.asarray(Y_scaled).astype('float32')\n",
    "print(Y_scaled.shape)\n",
    "X_train, X_test, Y_train,Y_test = train_test_split(X_scaled, Y_scaled, test_size=0.2, random_state=20)\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=2, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# model.summary()\n",
    "model.compile(loss='mse', optimizer='adam', metrics = ['mse','mae'])\n",
    "# # fit model\n",
    "history = model.fit(X_train, Y_train, batch_size=128, epochs=200, verbose=1, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b9636d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddb1822f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/217 [==============================] - 0s 365us/step - loss: 0.0842 - mse: 0.0842 - mae: 0.2255\n",
      "0.2901685\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def evaluate_nn(X,Y):\n",
    "    #evaluate on test dataset\n",
    "    Y_preds = model.predict(X)\n",
    "    # R2 = model.score(X_tests, Y_tests)\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(Y, Y_preds))\n",
    "    test_loss = model.evaluate(X, Y)\n",
    "    return RMSE, test_loss\n",
    "RMSE, test_loss = evaluate_nn(X_test,Y_test)\n",
    "print(RMSE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
