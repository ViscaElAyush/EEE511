{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de1f0cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "\n",
    "%reload_ext tensorboard\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.keras import initializers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.python.keras.optimizer_v2.adam import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pickle\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import tensorboard\n",
    "tensorboard.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7af343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(y_true, y_pred, clip_delta=1.0):\n",
    "        error = y_true - y_pred\n",
    "        cond  = tf.keras.backend.abs(error) < clip_delta\n",
    "        squared_loss = 0.5 * tf.keras.backend.square(error)\n",
    "        linear_loss  = clip_delta * (tf.keras.backend.abs(error) - 0.5 * clip_delta)\n",
    "        return tf.where(cond, squared_loss, linear_loss)\n",
    "def undummify(df, prefix_sep=\"_\"):\n",
    "    cols2collapse = {\n",
    "        item.split(prefix_sep)[0]: (prefix_sep in item) for item in df.columns\n",
    "    }\n",
    "    series_list = []\n",
    "    for col, needs_to_collapse in cols2collapse.items():\n",
    "        if needs_to_collapse:\n",
    "            undummified = (\n",
    "                df.filter(like=col)\n",
    "                .idxmax(axis=1)\n",
    "                .apply(lambda x: x.split(prefix_sep, maxsplit=1)[1])\n",
    "                .rename(col)\n",
    "            )\n",
    "            series_list.append(undummified)\n",
    "        else:\n",
    "            series_list.append(df[col])\n",
    "    undummified_df = pd.concat(series_list, axis=1)\n",
    "    return undummified_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9671ac47",
   "metadata": {},
   "source": [
    "### 1) Read dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a79f9d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseData = pd.read_csv('./Data/summer_limited.csv')\n",
    "BaseData = BaseData.drop(columns = ['Unnamed: 0'])\n",
    "# Copy Data for AirTemp & AbsHum scenarios before performing operation on AirTemp & AbsHum for BaseData\n",
    "AirTempMinus1 = BaseData.copy()\n",
    "AbsHumMinus1 = BaseData.copy()\n",
    "AllScen = BaseData.copy()\n",
    "# Perform operation on AirTemp & AbsHum then Copy Data to Shade Scenarios\n",
    "BaseData['Air Temp Squared'] = BaseData['Air Temp']**2\n",
    "BaseData['Abs Hum Squared'] = BaseData['Abs Hum']**2\n",
    "BaseData['Air Temp x Abs Hum'] = BaseData['Air Temp']*BaseData['Abs Hum']\n",
    "WestShade25 = BaseData.copy()\n",
    "EastShade25 = BaseData.copy()\n",
    "NorthShade25 = BaseData.copy()\n",
    "SouthShade25 = BaseData.copy()\n",
    "AllShade25 = BaseData.copy()\n",
    "# Perform operation for shade scenarios \n",
    "WestShade25.loc[WestShade25['Shade West'] < 1, 'Shade West'] = WestShade25['Shade West'] + WestShade25['Shade West']*0.25\n",
    "EastShade25.loc[EastShade25['Shade East'] < 1, 'Shade East'] = EastShade25['Shade East'] + EastShade25['Shade East']*0.25\n",
    "NorthShade25.loc[NorthShade25['Shade North'] < 1, 'Shade North'] = NorthShade25['Shade North'] + NorthShade25['Shade North']*0.25\n",
    "SouthShade25.loc[SouthShade25['Shade South'] < 1, 'Shade South'] = SouthShade25['Shade South'] + SouthShade25['Shade South']*0.25\n",
    "\n",
    "AllShade25.loc[AllShade25['Shade West'] < 1, 'Shade West'] = AllShade25['Shade West'] + AllShade25['Shade West']*0.25\n",
    "AllShade25.loc[AllShade25['Shade East'] < 1, 'Shade East'] = AllShade25['Shade East'] + AllShade25['Shade East']*0.25\n",
    "AllShade25.loc[AllShade25['Shade North'] < 1, 'Shade North'] = AllShade25['Shade North'] + AllShade25['Shade North']*0.25\n",
    "AllShade25.loc[AllShade25['Shade South'] < 1, 'Shade South'] = AllShade25['Shade South'] + AllShade25['Shade South']*0.25\n",
    "# Perform operation for AirTempMinus1, AbsHumMinus1, and AllScenarios\n",
    "AirTempMinus1['Air Temp'] = AirTempMinus1['Air Temp'] - 1\n",
    "AirTempMinus1['Air Temp Squared'] = AirTempMinus1['Air Temp']**2\n",
    "AirTempMinus1['Abs Hum Squared'] = AirTempMinus1['Abs Hum']**2\n",
    "AirTempMinus1['Air Temp x Abs Hum'] = AirTempMinus1['Air Temp']*AirTempMinus1['Abs Hum']\n",
    "\n",
    "AbsHumMinus1['Abs Hum'] = AbsHumMinus1['Abs Hum'] - 1\n",
    "AbsHumMinus1['Air Temp Squared'] = AbsHumMinus1['Air Temp']**2\n",
    "AbsHumMinus1['Abs Hum Squared'] = AbsHumMinus1['Abs Hum']**2\n",
    "AbsHumMinus1['Air Temp x Abs Hum'] = AbsHumMinus1['Air Temp']*AbsHumMinus1['Abs Hum']\n",
    "\n",
    "AllScen['Air Temp'] = AllScen['Air Temp'] - 1\n",
    "AllScen['Abs Hum'] = AllScen['Abs Hum'] - 1\n",
    "AllScen['Air Temp Squared'] = AllScen['Air Temp']**2\n",
    "AllScen['Abs Hum Squared'] = AllScen['Abs Hum']**2\n",
    "AllScen['Air Temp x Abs Hum'] = AllScen['Air Temp']*AllScen['Abs Hum']\n",
    "AllScen.loc[AllScen['Shade West'] < 1, 'Shade West'] = AllScen['Shade West'] + AllScen['Shade West']*0.25\n",
    "AllScen.loc[AllScen['Shade East'] < 1, 'Shade East'] = AllScen['Shade East'] + AllScen['Shade East']*0.25\n",
    "AllScen.loc[AllScen['Shade North'] < 1, 'Shade North'] = AllScen['Shade North'] + AllScen['Shade North']*0.25\n",
    "AllScen.loc[AllScen['Shade South'] < 1, 'Shade South'] = AllScen['Shade South'] + AllScen['Shade South']*0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92cc9bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data(setData):\n",
    "    #add extra features\n",
    "    X = setData[['bldgname',\n",
    "                  'Air Temp', \n",
    "                  'Abs Hum',\n",
    "                  'Air Temp Squared',\n",
    "                  'Abs Hum Squared',\n",
    "                  'Air Temp x Abs Hum',\n",
    "                  'DSW Top', \n",
    "                  'DSW North', \n",
    "                  'DSW South', \n",
    "                  'DSW East', \n",
    "                  'DSW West', \n",
    "                  'Shade North', \n",
    "                  'Shade East', \n",
    "                  'Shade West',\n",
    "                  'Shade South']]\n",
    "    columns = ['Air Temp', 'Abs Hum', 'Air Temp Squared',\n",
    "                'Abs Hum Squared', 'Air Temp x Abs Hum', 'DSW Top',\n",
    "               'DSW North', 'DSW South', 'DSW East','DSW West',\n",
    "               'Shade North', 'Shade East', 'Shade West', 'Shade South',]\n",
    "    Y = setData['CHWTON/SQFT']\n",
    "    Y = Y.values.reshape(-1, 1)    \n",
    "    Y = yscaler .fit_transform(Y)\n",
    "    X = pd.get_dummies(X)\n",
    "    X[columns] = xscaler.fit_transform(X[columns])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=20)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "641dcb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(BaseData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb6307",
   "metadata": {},
   "source": [
    "### 2) Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a00d465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 30)                780       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 40)                1240      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 50)                2050      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 5,761\n",
      "Trainable params: 5,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=25, activation= 'relu'))\n",
    "model.add(Dense(40, activation = 'relu'))\n",
    "model.add(Dense(40, activation = 'relu'))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "model.compile( loss = 'mse', optimizer = 'adam')\n",
    "model.summary()\n",
    "history = model.fit(X_train,y_train, \n",
    "                            batch_size=128, \n",
    "                            epochs=200, \n",
    "                            verbose=0, \n",
    "                            validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4a7e99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE score for test dataset of  0.11950383593962852\n",
      "The R2 score for test dataset of  0.986149961710786\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_preds))\n",
    "R2_score = metrics.r2_score(y_test, y_preds)\n",
    "print(\"The RMSE score for test dataset of \", RMSE)\n",
    "print(\"The R2 score for test dataset of \" ,R2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06b13f2",
   "metadata": {},
   "source": [
    "## Run below script only once after training. Before running script below, run scripts: 1, 2 and 3(whichever required) , and then run whole cycle again if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ff18f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bldg in range(len(Buildings)):\n",
    "    # plot predictions for baseline data data\n",
    "    date_time = MicroclimateData[['Date_Time',\n",
    "                            'Month',\n",
    "                            'Day',\n",
    "                            'Hour',\n",
    "                            'Minute']]\n",
    "    #for baseline results\n",
    "    yscaler = StandardScaler()\n",
    "    xscaler = StandardScaler()\n",
    "    X_train, X_test, y_train, y_test = prepare_data(BaseData)\n",
    "\n",
    "    comb1 = [X_train, X_test]\n",
    "    X_train= pd.concat(comb1)\n",
    "    #     print(\"old X\",X_train)\n",
    "    Y_preds = model.predict(X_train)\n",
    "    y_train = np.concatenate((y_train, y_test))\n",
    "    results_NN = undummify(X_train).join(date_time)\n",
    "    results_NN['Baseline'] = yscaler.inverse_transform(Y_preds)\n",
    "\n",
    "\n",
    "    #for new data results\n",
    "    X_train, X_test, y_train, y_test = prepare_data(EastShade25)\n",
    "    comb2 = [X_train, X_test]\n",
    "    X_train = pd.concat(comb2)\n",
    "    # print(\"new X\",X_train_new)\n",
    "    Y_preds = model.predict(X_train)\n",
    "    # print(\"new result\", Y_preds_new)\n",
    "    results_NN['Predicted with change'] = yscaler.inverse_transform(Y_preds)\n",
    "#     print(Y_preds_new)\n",
    "    \n",
    "    \n",
    "    # find out for particular day\n",
    "    month_NN = results_NN[results_NN['Month'] == 6]\n",
    "    day_NN = month_NN[month_NN['Day'] == 7]\n",
    "    bldg_NN = day_NN.loc[day_NN['bldgname'] == Buildings[bldg]]\n",
    "    bldg_NN['Time'] = bldg_NN['Date_Time'].str[11:16]  \n",
    "    # print(bldg_NN)\n",
    "    values_NN = bldg_NN.sort_values(by=['Time'])\n",
    "    values_NN['Model Predictions on Baseline Data']= values_NN['Baseline'] \n",
    "#     values_NN['Model predictions after reducing temperature']= values_NN['Predicted with change'] \n",
    "    # #plot values_NN\n",
    "    ax = values_NN.plot(x='Time',y='Model Predictions on Baseline Data',grid = False, figsize = (8,8))\n",
    "#     values_NN.plot(x='Time',y='Baseline',grid = False, figsize = (8,8),ax=ax)\n",
    "    values_NN.plot(x='Time',y='Predicted with change',grid = False, figsize = (8,8),ax=ax)\n",
    "    string = './Data/Plots/sensitivity analysis/7-6/WithShadeMod/East/'+ Buildings[bldg]\n",
    "    \n",
    "    plt.savefig(string, bbox_inches='tight')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b397e5ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2240484206.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_8038/2240484206.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    X_train, X_test, y_train, y_test = prepare_data(EastShade25)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a79673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8001014a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
