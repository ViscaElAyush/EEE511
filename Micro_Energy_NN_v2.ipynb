{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf63091",
   "metadata": {
    "id": "bbf63091"
   },
   "source": [
    "Build a baseline model using the weather station data (this approach used all days in 2018 since the data was available).\n",
    "\n",
    "\n",
    "Then use the model to make predictions for the ENVI-met(micro-climate) data for that specific day and compare it to model predictions using weather station data also for the same day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brVU4MWHtTtG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brVU4MWHtTtG",
    "outputId": "c9007d69-010c-4554-e25d-e59eeda5fdc0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a67839",
   "metadata": {
    "id": "c4a67839"
   },
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8ff5f4a1",
   "metadata": {
    "id": "8ff5f4a1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pickle\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "# train-test split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2323f8cd",
   "metadata": {
    "id": "2323f8cd"
   },
   "source": [
    "# 2. Load All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4dAfrWuqVMmj",
   "metadata": {
    "id": "4dAfrWuqVMmj"
   },
   "outputs": [],
   "source": [
    "# LIMITED DATA\n",
    "Bldg_Lim = []\n",
    "\n",
    "# Read all building data and append to list\n",
    "for path in pathlib.Path(\"./Data/microclimate_model/Combined/dataset3\").iterdir():\n",
    "        if path.is_file():\n",
    "            current_file = pd.read_csv(path)\n",
    "            current_file = current_file.drop(columns=['Unnamed: 0'])\n",
    "            Bldg_Lim.append(current_file)\n",
    "\n",
    "# BIG DATA\n",
    "Bldg_Big = []\n",
    "\n",
    "# Read all building data and append to list\n",
    "for path in pathlib.Path(\"./Data/NN_big_data\").iterdir():\n",
    "        if path.is_file():\n",
    "            current_file = pd.read_csv(path)\n",
    "            current_file = current_file.drop(columns=['Unnamed: 0'])\n",
    "            Bldg_Big.append(current_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XlKakizwVW6J",
   "metadata": {
    "id": "XlKakizwVW6J"
   },
   "source": [
    "## 2.1 Preprocessing\n",
    "\n",
    "1. Adding Month, Hour, and Minute to limited data\n",
    "2. Removing hours out of ENVI-met accuracy range (after 9 pm) for limited data\n",
    "3. Add CHWTON/SQFT to columns using condition area for each building taken from\n",
    "    https://fdm-apps.asu.edu/UFRM/FDS/FacilityData.aspx\n",
    "4. Drop na rows in limited data (some data points from campus metabolism not available)\n",
    "5. Drop 'index' column and rename 'rel humid' to 'rel hum' for big data\n",
    "6. Calculate and create new column for absolute humidity using equations from https://www.hatchability.com/Vaisala.pdf which can be validated using https://planetcalc.com/2167/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "oNbjTFZDVeQj",
   "metadata": {
    "id": "oNbjTFZDVeQj"
   },
   "outputs": [],
   "source": [
    "## LIMITED DATA ##\n",
    "# Create Month, Hour, and Minute column for all dataframes in list and drop unnecessary columns\n",
    "for i in range(len(Bldg_Lim)):\n",
    "    Bldg_Lim[i].Date_Time = pd.to_datetime(Bldg_Lim[i].Date_Time)\n",
    "    Bldg_Lim[i]['Month'] = Bldg_Lim[i].Date_Time.dt.month\n",
    "    Bldg_Lim[i]['Hour'] = Bldg_Lim[i].Date_Time.dt.hour\n",
    "    Bldg_Lim[i]['Minute'] = Bldg_Lim[i].Date_Time.dt.minute\n",
    "    Bldg_Lim[i]['Day'] = Bldg_Lim[i].Date_Time.dt.day\n",
    "    Bldg_Lim[i] = Bldg_Lim[i].drop(columns = ['Date_Time'])\n",
    "\n",
    "# Remove data after 9pm\n",
    "for i in range(len(Bldg_Lim)):\n",
    "    Bldg_Lim[i] = Bldg_Lim[i][(Bldg_Lim[i]['Hour'] <= 20) & (Bldg_Lim[i]['Hour'] > 0)]\n",
    "\n",
    "# Add Column: CHWTON/Condition Area (SqFt) or ['CHWTON/SQFT']\n",
    "cond_area = {'Noble Library':88658,'Biodesign B':132215,'Biodesign C':145410,\n",
    "             'Biodesign A':133016,'Psychology':69864,'Goldwater':165237,'Schwada COB':99857,\n",
    "             'ISTB 2':41404,'Bulldog Hall':68067,'ISTB 4':231646,'Psychology North':43034}\n",
    "for i in range(len(Bldg_Lim)):\n",
    "    if Bldg_Lim[i]['bldgname'][0] in cond_area:\n",
    "        Bldg_Lim[i]['CHWTON/SQFT'] = Bldg_Lim[i]['CHWTON'] / cond_area[Bldg_Lim[i]['bldgname'][0]]\n",
    "\n",
    "# Drop NA rows in data\n",
    "for i in range(len(Bldg_Lim)):\n",
    "  Bldg_Lim[i] = Bldg_Lim[i].dropna()\n",
    "  Bldg_Lim[i] = Bldg_Lim[i].reset_index(drop=True)\n",
    "\n",
    "## BIG DATA ##\n",
    "# Rename 'Rel Humid' to 'Rel Hum' and drop 'index' column\n",
    "for i in range(len(Bldg_Big)):\n",
    "  Bldg_Big[i] = Bldg_Big[i].rename(columns = {'Rel Humid': 'Rel Hum'})\n",
    "  Bldg_Big[i] = Bldg_Big[i].drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0YVaY6zNaoVM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0YVaY6zNaoVM",
    "outputId": "789806cb-a495-49d8-ac18-3ea40d17f590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [bldgname, Date, Time, Air Temp, Rel Hum, KW, CHWTON, HTmmBTU, Month, Hour, Minute, Day, CHWTON/SQFT]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [bldgname, Date, Time, Air Temp, Rel Hum, KW, CHWTON, HTmmBTU, Month, Hour, Minute, Day, CHWTON/SQFT]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [bldgname, Date, Time, Air Temp, Rel Hum, KW, CHWTON, HTmmBTU, Month, Hour, Minute, Day, CHWTON/SQFT]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [bldgname, Date, Time, Air Temp, Rel Hum, KW, CHWTON, HTmmBTU, Month, Hour, Minute, Day, CHWTON/SQFT]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [bldgname, Date, Time, Air Temp, Rel Hum, KW, CHWTON, HTmmBTU, Month, Hour, Minute, Day, CHWTON/SQFT]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [bldgname, Date, Time, Air Temp, Rel Hum, KW, CHWTON, HTmmBTU, Month, Hour, Minute, Day, CHWTON/SQFT]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [bldgname, Date, Time, Air Temp, Rel Hum, KW, CHWTON, HTmmBTU, Month, Hour, Minute, Day, CHWTON/SQFT]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [bldgname, Date, Time, Air Temp, Rel Hum, KW, CHWTON, HTmmBTU, Month, Hour, Minute, Day, CHWTON/SQFT]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [bldgname, Date, Time, Air Temp, Rel Hum, KW, CHWTON, HTmmBTU, Month, Hour, Minute, Day, CHWTON/SQFT]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [bldgname, Date, Time, Air Temp, Rel Hum, KW, CHWTON, HTmmBTU, Month, Hour, Minute, Day, CHWTON/SQFT]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [bldgname, Date, Time, Air Temp, Rel Hum, KW, CHWTON, HTmmBTU, Month, Hour, Minute, Day, CHWTON/SQFT]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check if NA in data\n",
    "for i in range(len(Bldg_Lim)):\n",
    "  null_data = Bldg_Lim[i][Bldg_Lim[i].isnull().any(axis=1)]\n",
    "  print(null_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6BDWQ5D-tQfJ",
   "metadata": {
    "id": "6BDWQ5D-tQfJ"
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "P_c = 220640\n",
    "T_c = 647.096\n",
    "C_1 = -7.85951783\n",
    "C_2 = 1.84408259\n",
    "C_3 =  -11.7866497\n",
    "C_4 = 22.6807411\n",
    "C_5 = -15.9618719\n",
    "C_6 = 1.80122502\n",
    "C = 2.16679\n",
    "\n",
    "# Convert Rel Hum to Abs Hum for Limited Data\n",
    "for i in range(len(Bldg_Lim)):\n",
    "    T_i = Bldg_Lim[i]['Air Temp']\n",
    "    RH = Bldg_Lim[i]['Rel Hum']/100\n",
    "    T = T_i + 273.15\n",
    "    v = 1 - (T/T_c)\n",
    "    x = (T_c/T)*((C_1*v) + (C_2*np.power(v, 1.5)) + (C_3*np.power(v, 3)) \n",
    "                 + (C_4*np.power(v, 3.5)) + (C_5*np.power(v, 4)) + (C_6*np.power(v, 7.5))) \n",
    "    P_ws = np.exp(x)*P_c\n",
    "    P_w = P_ws*RH\n",
    "    A = C*P_w*100/T\n",
    "    Bldg_Lim[i]['Abs Hum'] = A\n",
    "\n",
    "# Convert Rel Hum to Abs Hum for Big Data\n",
    "for i in range(len(Bldg_Big)):\n",
    "    T_i = Bldg_Big[i]['Air Temp']\n",
    "    RH = Bldg_Big[i]['Rel Hum']/100\n",
    "    T = T_i + 273.15\n",
    "    v = 1 - (T/T_c)\n",
    "    x = (T_c/T)*((C_1*v) + (C_2*np.power(v, 1.5)) + (C_3*np.power(v, 3)) \n",
    "                 + (C_4*np.power(v, 3.5)) + (C_5*np.power(v, 4)) + (C_6*np.power(v, 7.5))) \n",
    "    P_ws = np.exp(x)*P_c\n",
    "    P_w = P_ws*RH\n",
    "    A = C*P_w*100/T\n",
    "    Bldg_Big[i]['Abs Hum'] = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "XYH50jCYtprE",
   "metadata": {
    "id": "XYH50jCYtprE"
   },
   "outputs": [],
   "source": [
    "## Rearrange Columns\n",
    "\n",
    "# For Limited Data\n",
    "for i in range(len(Bldg_Lim)):\n",
    "    cols = ['bldgname','Date','Time','Month','Day','Hour','Minute','Air Temp','Abs Hum', 'Rel Hum','KW','CHWTON','CHWTON/SQFT']\n",
    "    Bldg_Lim[i] = Bldg_Lim[i][cols]\n",
    "\n",
    "# For Big Data\n",
    "for i in range(len(Bldg_Big)):\n",
    "    cols = ['bldgname','Month','Day','Hour','Minute','Air Temp','Abs Hum', 'Rel Hum','KW','CHWTON','CHWTON/SQFT']\n",
    "    Bldg_Big[i] = Bldg_Big[i][cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1umRuw8lsTqQ",
   "metadata": {
    "id": "1umRuw8lsTqQ"
   },
   "source": [
    "# 3. Single Building Analysis - Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j5l5AuKIsVl4",
   "metadata": {
    "id": "j5l5AuKIsVl4"
   },
   "source": [
    "## 3.1 Select Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "GSwktBAaepBb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "id": "GSwktBAaepBb",
    "outputId": "391f3587-0629-49f1-a528-e3b938e7e62a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Goldwater\n",
      "1 Bulldog Hall\n",
      "2 ISTB 2\n",
      "3 Psychology North\n",
      "4 Schwada COB\n",
      "5 Biodesign C\n",
      "6 Biodesign A\n",
      "7 Psychology\n",
      "8 Biodesign B\n",
      "9 Noble Library\n",
      "10 ISTB 4\n",
      "Enter the number of the building from the list above: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bldgname</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Air Temp</th>\n",
       "      <th>Abs Hum</th>\n",
       "      <th>Rel Hum</th>\n",
       "      <th>KW</th>\n",
       "      <th>CHWTON</th>\n",
       "      <th>CHWTON/SQFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.028567</td>\n",
       "      <td>40.24</td>\n",
       "      <td>890.33</td>\n",
       "      <td>70.48</td>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.028567</td>\n",
       "      <td>40.24</td>\n",
       "      <td>891.28</td>\n",
       "      <td>59.73</td>\n",
       "      <td>0.000258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.042106</td>\n",
       "      <td>43.01</td>\n",
       "      <td>886.57</td>\n",
       "      <td>64.01</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.056162</td>\n",
       "      <td>46.00</td>\n",
       "      <td>886.66</td>\n",
       "      <td>63.49</td>\n",
       "      <td>0.000274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.056162</td>\n",
       "      <td>46.00</td>\n",
       "      <td>880.12</td>\n",
       "      <td>68.87</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34618</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.773487</td>\n",
       "      <td>93.30</td>\n",
       "      <td>951.10</td>\n",
       "      <td>69.14</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34619</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.797015</td>\n",
       "      <td>100.00</td>\n",
       "      <td>952.58</td>\n",
       "      <td>70.95</td>\n",
       "      <td>0.000306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34620</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.797015</td>\n",
       "      <td>100.00</td>\n",
       "      <td>937.86</td>\n",
       "      <td>68.62</td>\n",
       "      <td>0.000296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34621</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.773487</td>\n",
       "      <td>93.30</td>\n",
       "      <td>941.16</td>\n",
       "      <td>70.36</td>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34622</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.773487</td>\n",
       "      <td>93.30</td>\n",
       "      <td>941.79</td>\n",
       "      <td>73.25</td>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34623 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bldgname  Month  Day  Hour  Minute  Air Temp   Abs Hum  Rel Hum      KW  \\\n",
       "0       ISTB 4      1    1     0       0      11.0  4.028567    40.24  890.33   \n",
       "1       ISTB 4      1    1     0      15      11.0  4.028567    40.24  891.28   \n",
       "2       ISTB 4      1    1     0      30      10.0  4.042106    43.01  886.57   \n",
       "3       ISTB 4      1    1     0      45       9.0  4.056162    46.00  886.66   \n",
       "4       ISTB 4      1    1     1       0       9.0  4.056162    46.00  880.12   \n",
       "...        ...    ...  ...   ...     ...       ...       ...      ...     ...   \n",
       "34618   ISTB 4     12   31    22       0       6.0  6.773487    93.30  951.10   \n",
       "34619   ISTB 4     12   31    22      15       5.0  6.797015   100.00  952.58   \n",
       "34620   ISTB 4     12   31    22      30       5.0  6.797015   100.00  937.86   \n",
       "34621   ISTB 4     12   31    22      45       6.0  6.773487    93.30  941.16   \n",
       "34622   ISTB 4     12   31    23       0       6.0  6.773487    93.30  941.79   \n",
       "\n",
       "       CHWTON  CHWTON/SQFT  \n",
       "0       70.48     0.000304  \n",
       "1       59.73     0.000258  \n",
       "2       64.01     0.000276  \n",
       "3       63.49     0.000274  \n",
       "4       68.87     0.000297  \n",
       "...       ...          ...  \n",
       "34618   69.14     0.000298  \n",
       "34619   70.95     0.000306  \n",
       "34620   68.62     0.000296  \n",
       "34621   70.36     0.000304  \n",
       "34622   73.25     0.000316  \n",
       "\n",
       "[34623 rows x 11 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask user to select building\n",
    "for i in range(len(Bldg_Big)):\n",
    "    print(i, Bldg_Big[i]['bldgname'][0])\n",
    "\n",
    "bldgnum_B = int(input(\"Enter the number of the building from the list above: \"))\n",
    "\n",
    "Bldg_Big[bldgnum_B]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FcP5TbQ5skSV",
   "metadata": {
    "id": "FcP5TbQ5skSV"
   },
   "source": [
    "## 3.2 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l2LsyH43sY-R",
   "metadata": {
    "id": "l2LsyH43sY-R"
   },
   "source": [
    "### 3.2.1 Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XU5wq_f7fIib",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 849
    },
    "id": "XU5wq_f7fIib",
    "outputId": "df413896-5b6a-4b38-8bef-95fd406c0539"
   },
   "outputs": [],
   "source": [
    "# Show df columns to select for boxplot\n",
    "x = Bldg_Big[bldgnum_B].columns\n",
    "for i in range(len(x)):\n",
    "    print(i, x[i])\n",
    "# Get column name from user\n",
    "colname = int(input(\"Enter the number of the following data columns to graph boxplot: \"))\n",
    "# Plot\n",
    "print('\\n',Bldg_Big[bldgnum_B]['bldgname'][0])\n",
    "Bldg_Big[bldgnum_B].boxplot(by='Month', column=x[colname], grid = False, figsize = (8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bkjN8CdtYgA",
   "metadata": {
    "id": "1bkjN8CdtYgA"
   },
   "source": [
    "### 3.2.2 Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ukK2WxsztWuD",
   "metadata": {
    "id": "ukK2WxsztWuD"
   },
   "outputs": [],
   "source": [
    "### will work on create Date and Time column for big data to visualize vs Limited Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d68606",
   "metadata": {
    "id": "35d68606"
   },
   "source": [
    "# 4. Single Building Analysis - Limited Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nDGlxtORWiit",
   "metadata": {
    "id": "nDGlxtORWiit"
   },
   "source": [
    "## 4.1 Select Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "EXFKvTh7Wen5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "EXFKvTh7Wen5",
    "outputId": "809c609f-116a-4c71-fc25-741e8fd86399"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Goldwater\n",
      "1 Bulldog Hall\n",
      "2 ISTB 2\n",
      "3 Psychology North\n",
      "4 Schwada COB\n",
      "5 Biodesign C\n",
      "6 Biodesign A\n",
      "7 Psychology\n",
      "8 Biodesign B\n",
      "9 Noble Library\n",
      "10 ISTB 4\n",
      "Enter the number of the building from the list above: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bldgname</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Air Temp</th>\n",
       "      <th>Abs Hum</th>\n",
       "      <th>Rel Hum</th>\n",
       "      <th>KW</th>\n",
       "      <th>CHWTON</th>\n",
       "      <th>CHWTON/SQFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>05:00</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>25.012220</td>\n",
       "      <td>4.430433</td>\n",
       "      <td>19.218981</td>\n",
       "      <td>902.76</td>\n",
       "      <td>337.88</td>\n",
       "      <td>0.001459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>05:15</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>24.671093</td>\n",
       "      <td>4.864263</td>\n",
       "      <td>21.510339</td>\n",
       "      <td>909.39</td>\n",
       "      <td>343.41</td>\n",
       "      <td>0.001482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>05:30</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>24.495274</td>\n",
       "      <td>4.786310</td>\n",
       "      <td>21.376736</td>\n",
       "      <td>904.81</td>\n",
       "      <td>348.91</td>\n",
       "      <td>0.001506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>05:45</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>24.375078</td>\n",
       "      <td>4.778235</td>\n",
       "      <td>21.486126</td>\n",
       "      <td>893.55</td>\n",
       "      <td>328.88</td>\n",
       "      <td>0.001420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>06:00</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>24.257700</td>\n",
       "      <td>4.793644</td>\n",
       "      <td>21.699019</td>\n",
       "      <td>892.93</td>\n",
       "      <td>329.80</td>\n",
       "      <td>0.001424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bldgname        Date   Time  Month  Day  Hour  Minute   Air Temp   Abs Hum  \\\n",
       "0   ISTB 4  2018-05-16  05:00      5   16     5       0  25.012220  4.430433   \n",
       "1   ISTB 4  2018-05-16  05:15      5   16     5      15  24.671093  4.864263   \n",
       "2   ISTB 4  2018-05-16  05:30      5   16     5      30  24.495274  4.786310   \n",
       "3   ISTB 4  2018-05-16  05:45      5   16     5      45  24.375078  4.778235   \n",
       "4   ISTB 4  2018-05-16  06:00      5   16     6       0  24.257700  4.793644   \n",
       "\n",
       "     Rel Hum      KW  CHWTON  CHWTON/SQFT  \n",
       "0  19.218981  902.76  337.88     0.001459  \n",
       "1  21.510339  909.39  343.41     0.001482  \n",
       "2  21.376736  904.81  348.91     0.001506  \n",
       "3  21.486126  893.55  328.88     0.001420  \n",
       "4  21.699019  892.93  329.80     0.001424  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask user to select building\n",
    "for i in range(len(Bldg_Lim)):\n",
    "    print(i, Bldg_Lim[i]['bldgname'][0])\n",
    "\n",
    "bldgnum_L = int(input(\"Enter the number of the building from the list above: \"))\n",
    "\n",
    "Bldg_Lim[bldgnum_L].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lBzm9pDRW2L2",
   "metadata": {
    "id": "lBzm9pDRW2L2"
   },
   "source": [
    "## 4.2 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qU-_AGApW59A",
   "metadata": {
    "id": "qU-_AGApW59A"
   },
   "source": [
    "### 4.2.1 Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5yj10zCHXrd2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "id": "5yj10zCHXrd2",
    "outputId": "15db540c-60d3-420a-d681-1b842a3bd2cc"
   },
   "outputs": [],
   "source": [
    "# Show df columns to select for boxplot\n",
    "x = Bldg_Lim[bldgnum_L].columns\n",
    "for i in range(len(x)):\n",
    "    print(i, x[i])\n",
    "# Get column name from user\n",
    "colname = int(input(\"Enter the number of the following data columns to graph boxplot: \"))\n",
    "# Plot\n",
    "print('\\n',Bldg_Lim[bldgnum_L]['bldgname'][0])\n",
    "Bldg_Lim[bldgnum_L].boxplot(by='Hour', column=x[colname], grid = False, figsize = (8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ZnkagfyYECY",
   "metadata": {
    "id": "5ZnkagfyYECY"
   },
   "source": [
    "### 4.2.2 Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yBl3v65SYIAu",
   "metadata": {
    "id": "yBl3v65SYIAu"
   },
   "source": [
    "Month available:<br>\n",
    "May: 16, 23 <br>\n",
    "June: 7, 8, 20, 21, 25<br>\n",
    "August: 3<br>\n",
    "September: 11, 29<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8GiSWYYeYF2F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8GiSWYYeYF2F",
    "outputId": "3cf93cac-c03f-46dc-afa0-36baa84ff014"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Get month number for plotting\n",
    "m_num = int(input(\"Enter month number: \"))\n",
    "# Convert to datetime to get month name\n",
    "datetime_object = datetime.datetime.strptime(str(m_num), \"%m\")\n",
    "m_name = datetime_object.strftime(\"%b\")\n",
    "\n",
    "# Plot only if entered month is in data\n",
    "if m_num in Bldg_Lim[bldgnum_L]['Month'].unique():\n",
    "    from datetime import datetime\n",
    "    # Assign new df for chosen month\n",
    "    plotdf = pd.DataFrame(Bldg_Lim[bldgnum_L][(Bldg_Lim[bldgnum_L]['Month'] == m_num)])\n",
    "    # Show number of days found in chosen month\n",
    "    x = plotdf['Date'].unique()\n",
    "    print(\"\\n\", len(x), \"day(s) found in\", m_name, \"\\n\")\n",
    "    # Show all columns to select y-axis for plotting\n",
    "    cols = plotdf.columns\n",
    "    for i in range(len(cols)):\n",
    "        print(i, cols[i])\n",
    "    # Get y-axis for plotting\n",
    "    y_ax = int(input('Enter y-axis from column list above: '))\n",
    "    y_ax = cols[y_ax]\n",
    "    for i in range(len(x)):\n",
    "        datetime_object = datetime.strptime(x[i], '%Y-%m-%d')\n",
    "        days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "        d = days[datetime_object.weekday()]\n",
    "        plotdf1 = plotdf[(plotdf['Date']==x[i])]\n",
    "        plotdf1.plot(x = 'Time', y = y_ax, grid = False, figsize = (8,8), title = x[i] + ' ' + d)\n",
    "else:\n",
    "    print(\"Month number not in data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O_LGJq45YwcF",
   "metadata": {
    "id": "O_LGJq45YwcF"
   },
   "source": [
    "### 4.2.3 Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ElBa562xYxm6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "ElBa562xYxm6",
    "outputId": "7a1006a9-0374-43d6-821a-46f0b6a559c6"
   },
   "outputs": [],
   "source": [
    "corr_pd = pd.DataFrame(Bldg_Lim[bldgnum_L][['Air Temp','Abs Hum', 'Rel Hum','KW', 'CHWTON/SQFT']])\n",
    "corrMatrix = corr_pd.corr()\n",
    "sns.heatmap(corrMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648884d9",
   "metadata": {
    "id": "648884d9"
   },
   "source": [
    "# 5. Train Models on both datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LYCunDz4szhq",
   "metadata": {
    "id": "LYCunDz4szhq"
   },
   "source": [
    "## 5.1 Define Generalized Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "023b6ba6",
   "metadata": {
    "id": "023b6ba6"
   },
   "outputs": [],
   "source": [
    "#using single layer ANN. Model Parameters: hidden layer- 10 neurons, output layer- 1 neuron\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.keras import initializers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import backend as K\n",
    "def prepare_data(dataset):\n",
    "    Y = dataset['CHWTON/SQFT']\n",
    "    X = dataset[['Air Temp', 'Abs Hum']]\n",
    "    Y= Y.values.reshape(-1, 1)\n",
    "    # create scaler\n",
    "    scaler1 = StandardScaler()\n",
    "    X_scaled = scaler1.fit_transform(X)\n",
    "    # #do for output variables\n",
    "    scaler2 = StandardScaler()\n",
    "    Y_scaled = scaler2.fit_transform(Y)\n",
    "    X_scaled = np.asarray(X_scaled).astype('float32')\n",
    "    Y_scaled = np.asarray(Y_scaled).astype('float32')\n",
    "    return X_scaled,Y_scaled\n",
    "\n",
    "def huber_loss(y_true, y_pred, clip_delta=1.0):\n",
    "    error = y_true - y_pred\n",
    "    cond  = tf.keras.backend.abs(error) < clip_delta\n",
    "    squared_loss = 0.5 * tf.keras.backend.square(error)\n",
    "    linear_loss  = clip_delta * (tf.keras.backend.abs(error) - 0.5 * clip_delta)\n",
    "    return tf.where(cond, squared_loss, linear_loss)\n",
    "\n",
    "'''\n",
    " ' Same as above but returns the mean loss.\n",
    "'''\n",
    "def huber_loss_mean(y_true, y_pred, clip_delta=1.0):\n",
    "    return tf.keras.backend.mean(huber_loss(y_true, y_pred, clip_delta))\n",
    "\n",
    "def define_model(activation_type, hidden_layers, loss, kernel_initializer='he_normal', bias_initializer='he_normal'):\n",
    "    model = Sequential()\n",
    "    if activation_type == 'leaky_relu':\n",
    "        model.add(Dense(10, input_dim=2, kernel_initializer='he_normal'))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        for i in range(0,(hidden_layers-2)):\n",
    "            model.add(Dense(8))\n",
    "            model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(Dense(16))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "    else:\n",
    "        model.add(Dense(10, input_dim=2, kernel_initializer='he_normal', bias_initializer='he_normal', activation=activation_type))\n",
    "        for i in range(0,(hidden_layers-2)):\n",
    "            model.add(Dense(8, activation=activation_type))\n",
    "        model.add(Dense(12, activation=activation_type))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss= loss, optimizer='adam', metrics = ['mse','mae'])\n",
    "#     model.summary()\n",
    "    return model\n",
    "def fine_tune(model,loss):\n",
    "    model.trainable = True\n",
    "    fine_tune_at = 2\n",
    "    for layer in model.layers[:fine_tune_at]:\n",
    "      layer.trainable =  False\n",
    "    model.compile(loss=loss, optimizer='adam', metrics = ['mse','mae'])\n",
    "    return model\n",
    "def plot_curve(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "def evaluate(model,X,Y):\n",
    "    #evaluate on test dataset, add evaluation parameters\n",
    "    Y_preds = model.predict(X)\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(Y, Y_preds))\n",
    "    R2_score = metrics.r2_score(Y, Y_preds)\n",
    "#     test_loss = model.evaluate(X, Y)\n",
    "    return RMSE, R2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f211eeb",
   "metadata": {
    "id": "4f211eeb"
   },
   "source": [
    "## 5.2 Prepare Data for feeding into training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "IWQN1vHce_Kq",
   "metadata": {
    "id": "IWQN1vHce_Kq"
   },
   "outputs": [],
   "source": [
    "# Limited Data\n",
    "X_limited,Y_limited = prepare_data(Bldg_Lim[bldgnum_L])\n",
    "X_limited_train, X_limited_test, Y_limited_train,Y_limited_test = train_test_split(X_limited,Y_limited , test_size=0.2, random_state=20)\n",
    "X,Y = prepare_data(Bldg_Big[bldgnum_B])\n",
    "X_train, X_test, Y_train,Y_test = train_test_split(X, Y, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "eT4jtNIjxilZ",
   "metadata": {
    "id": "eT4jtNIjxilZ"
   },
   "outputs": [],
   "source": [
    "# X_limited_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a18fd",
   "metadata": {
    "id": "117a18fd"
   },
   "source": [
    "## 5.3 Hyperparameter Tuning experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "394685f8",
   "metadata": {
    "id": "394685f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find parameters for Goldwater\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.9317104992895349\n",
      "Updated hyperparameters for building: Goldwatermax_R2:0.9317104992895349: Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.920965073409049\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.8518559000709084\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9287241403581608\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9136771876392691\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.9122093033287559\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.9244020214557924\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.9102899528537526\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9161748766534527\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9217933867840489\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.9147072059647634\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.9153855919341656\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.9007534487218307\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9287536658607634\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9193471895371957\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.9329044545695684\n",
      "Updated hyperparameters for building: Goldwatermax_R2:0.9329044545695684: Activation Fn: elu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.9231470381305532\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.8786210233832938\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.929037059273208\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.929076094555454\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.9224938260476748\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.9206624443057987\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.5316953008459256\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.924438977150443\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9275864231209358\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.9249397737773959\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.9187161642044098\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.8749018251014082\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9256751429441098\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9248450489205442\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.9281563406363033\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.9226038510537549\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.689717974418367\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9255239423565532\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9289409141644493\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.9281292149326356\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.9139271583525507\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.8500587117083781\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9306311825630346\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9294517945628485\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.9233682183368579\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.9255563635075256\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.8465747656862319\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9261637752488814\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9177758019892983\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.9255412582221831\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.9156882756695732\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.8404265069090701\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9179797602469586\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9296075314981707\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.9290933549527112\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.9234289253589522\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.9043908737226666\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9264382291387224\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9255666180023271\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.9269383689118457\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.9202830642111659\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.9009466931881124\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.92599179846448\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.917580237269316\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.9262096671610343\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.9175984474657111\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.5972886999309581\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9280535845451443\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9298724400199703\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.9290626961247348\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.915320167253418\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.5330999711367823\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9173340672359515\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9261834208868029\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.9172420828195066\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.9121403825474662\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "-0.004905900914194294\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.917477194108228\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.930722232306373\n",
      "Find parameters for Bulldog Hall\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.49517428381512585\n",
      "Updated hyperparameters for building: Bulldog Hallmax_R2:0.49517428381512585: Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.4933900626468348\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.21907756338513495\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.48783296465604875\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.4972066424565995\n",
      "Updated hyperparameters for building: Bulldog Hallmax_R2:0.4972066424565995: Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.49968257540196326\n",
      "Updated hyperparameters for building: Bulldog Hallmax_R2:0.49968257540196326: Activation Fn: relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.4828706511589197\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.23796362026525109\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5003928173674621\n",
      "Updated hyperparameters for building: Bulldog Hallmax_R2:0.5003928173674621: Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5004220691593322\n",
      "Updated hyperparameters for building: Bulldog Hallmax_R2:0.5004220691593322: Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.514877964884001\n",
      "Updated hyperparameters for building: Bulldog Hallmax_R2:0.514877964884001: Activation Fn: relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.48492524137937487\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.19076098485099668\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.516826564021716\n",
      "Updated hyperparameters for building: Bulldog Hallmax_R2:0.516826564021716: Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5030493114604142\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.5022313510872345\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.4837136306945118\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.3065871461178694\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5112448757151675\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.515561431339546\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.5115784681317304\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.4952632147501418\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.22801383329194458\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.4910498327645739\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5075166035722677\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.5040665874937622\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.4735497284479141\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.2929253456677251\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.507432781085491\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.512842639405513\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.5206905385724254\n",
      "Updated hyperparameters for building: Bulldog Hallmax_R2:0.5206905385724254: Activation Fn: selu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.4886667239462611\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.27512018694015616\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.49575841060893844\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.4982443142262104\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.514092661328042\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.4898239513904368\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28269944042381556\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5104846877095746\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5143190586125834\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.5216873982610017\n",
      "Updated hyperparameters for building: Bulldog Hallmax_R2:0.5216873982610017: Activation Fn: selu #hidden_layers: 5 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.5108744173325184\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.32066429354371206\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5273695780823686\n",
      "Updated hyperparameters for building: Bulldog Hallmax_R2:0.5273695780823686: Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5224022367522498\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.4941050114823413\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.4740572534370594\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.28895121434861826\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5074340103366712\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5017833425135789\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.4941307682301209\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.4722179044101328\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.2852213545425454\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.515594506893938\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5066511724170663\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.5173184454349722\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.497491562545212\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.2545403671993345\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.4999742720757927\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5258388509566305\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.5039770991805463\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.47124224194627606\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.26637667757834305\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5084131277949153\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.500590120899878\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.5026797926109716\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.4724562038524014\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.29471127497125094\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5113928468475366\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5066277451440555\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.5010129067860132\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.4914294979548861\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.21760612770835097\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.521157124665602\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5153351809240525\n",
      "Find parameters for ISTB 2\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.874195653645829\n",
      "Updated hyperparameters for building: ISTB 2max_R2:0.874195653645829: Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.8718536458250024\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.869609488042067\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.871143166824621\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8646787800992719\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.8634140639389476\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.8704381921598043\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.872414841456448\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8673195821350478\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8614820951718734\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.8688387184049413\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.8642848282985223\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.8545961838514678\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8771077137724556\n",
      "Updated hyperparameters for building: ISTB 2max_R2:0.8771077137724556: Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8677971830327651\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.8641123638694641\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.8690839583412716\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.8448815834806531\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8669561046820328\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8718719558200092\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.8689625166182521\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.8735419064074662\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.8536395236403391\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8701424130701323\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8652203607734198\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.8696937271526841\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.869936564345138\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.8321199050541873\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8580883542541559\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8717558793595617\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.8667821237138584\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.8668574599627858\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.8383136477421123\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.864450613816816\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8671441822985841\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.8678761994758168\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.8720797688452468\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.8664585106425197\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8701029129246193\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8686513979328451\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.8681421835650662\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.8717246387013804\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.8542658826460767\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8615724157236714\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8633713839636286\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.8643494664908686\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.8711594819648882\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.8451396978105666\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8650123533818513\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8648573946099735\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.8673584812118049\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.8671768468531775\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.8492052024323749\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8677717207907493\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8588051516282317\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.8660297745849561\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.8757394864792716\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.8603077178815394\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8661571577660047\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8651475772718172\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.8703532415265607\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.8717655038358209\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.836198442883555\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8577697271245607\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8705588481831902\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.8641418808275967\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.8701080773588813\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.8653971088455432\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8685011448291262\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8683242090376173\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.8700851066474886\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.8660868026449541\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.8699227365487402\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8705508377490201\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8657296454079361\n",
      "Find parameters for Psychology North\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.7083098949183254\n",
      "Updated hyperparameters for building: Psychology Northmax_R2:0.7083098949183254: Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.6947078523697625\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.4716848651110488\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7182853703457539\n",
      "Updated hyperparameters for building: Psychology Northmax_R2:0.7182853703457539: Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7145774677277443\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.6974744161650561\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.6999705484388217\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.4734489457167469\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7203478427628556\n",
      "Updated hyperparameters for building: Psychology Northmax_R2:0.7203478427628556: Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7120863882262127\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.6880674365789903\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.7345123406428871\n",
      "Updated hyperparameters for building: Psychology Northmax_R2:0.7345123406428871: Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.5480671393282852\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7152458541318635\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7198932012384958\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.7471893597020076\n",
      "Updated hyperparameters for building: Psychology Northmax_R2:0.7471893597020076: Activation Fn: elu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.7219300172361593\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.3606951865393827\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7347171953098034\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.738545557337327\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.7160226266323844\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.7228210157750568\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.3882096714446829\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7354046947535463\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7184440319999613\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.7061705528578799\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.705376167753318\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.3613811791171485\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7110611834885712\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.6899422257412492\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.7278606269636717\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.7249969621407182\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.440661265704848\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7506826310820595\n",
      "Updated hyperparameters for building: Psychology Northmax_R2:0.7506826310820595: Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7320885170435136\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.7216624793689188\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.7294649340072915\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.32868111750531515\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7245247295818652\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7368970280328107\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.7258921333289449\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.6881225825700756\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.3298977778052232\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.6989231540595906\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7278745878947053\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.7280108253277076\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.7380045146153457\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.4099318658303548\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7300300844306985\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7225071263976462\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.730181328161732\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.725997817950531\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.4182687230221396\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7200146553194364\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7153411235967257\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.6946949303329082\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.7085363072158462\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.47358682158550536\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.6936013236925576\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.709166251825637\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.7093925025213521\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.7188358648197646\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_percentage_error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31162867094573377\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7234416520435536\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7087039141068183\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.7301921507753433\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.7125269937531025\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.4188275865550899\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7155241783251135\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.731054272093099\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.7223202469639833\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.7185904538493064\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.41120855706062975\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7183659717509373\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7144089694275537\n",
      "Find parameters for Schwada COB\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.8407298249899642\n",
      "Updated hyperparameters for building: Schwada COBmax_R2:0.8407298249899642: Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.8289566877245323\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.7065999035565139\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8364834641882768\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.828041029524218\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.8369717545044455\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.8471040844446539\n",
      "Updated hyperparameters for building: Schwada COBmax_R2:0.8471040844446539: Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.7286225054355413\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8358238555536062\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8427975027943322\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.8495869846227364\n",
      "Updated hyperparameters for building: Schwada COBmax_R2:0.8495869846227364: Activation Fn: relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.8305607619509027\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.7185563804913722\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8377169996858964\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8361092586531313\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.8352523551469748\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.8405679717354398\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.40700772740351454\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8335974583224703\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8426705585573512\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.8395266910409158\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.8337301236776268\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.6273333324134176\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8363211956044613\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8386834194439989\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.8447012470492086\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.8228406432573412\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.4533645949885923\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8394177753831629\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.84013366173984\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.8279098849117648\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.8231938184027051\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.4192584593531927\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8254551916899926\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8286768802778951\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.8451645724129129\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.8411034715225352\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.4805008361264579\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8315128324099447\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8349281604319896\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.8382538820949035\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.8358779149886679\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.5651773767039032\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8370791793981541\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8399187772847516\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.8489815095601343\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8462654595333698\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.597198362225573\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8359014179006858\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8491969575561232\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.8413476619930301\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.8409145162612456\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.6745003387241078\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8370968076582866\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.842229048122182\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.8310507350195064\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.828113153478315\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.7268413066482572\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8463351610609373\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8320423870904303\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.833431836142561\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.8249401514519861\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.5190322881781199\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8410224064890354\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8358445624395662\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.8336708494250897\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.827455983295363\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.3992100104854466\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8253594856338012\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8364258600584181\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.8479753980004113\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.8245239613849991\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.3042782475824495\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8375031110997254\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8380980638389768\n",
      "Find parameters for Biodesign C\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.43815585621569897\n",
      "Updated hyperparameters for building: Biodesign Cmax_R2:0.43815585621569897: Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.6608327643067259\n",
      "Updated hyperparameters for building: Biodesign Cmax_R2:0.6608327643067259: Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.39781065103023683\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5614214751190967\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.609317802488058\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.4313267209231696\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.6376299475961944\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.3629842634777608\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.6172944155512574\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.6228952361198414\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.34840865412005273\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.60378132442708\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.4061713446744596\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.485586145874605\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.4696494571708091\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.4298146212926436\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.6088743130483797\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.44837606900675\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.568306130165831\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5635622563839762\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.4121968992422881\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.5905225066970423\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.40511216187489385\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5824616887818813\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5315176492286311\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.2838233079020045\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.6691605949363961\n",
      "Updated hyperparameters for building: Biodesign Cmax_R2:0.6691605949363961: Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.43547353561424773\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.4512220970181863\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.4557537314273379\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_squared_error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4658813831577342\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.5901591879409358\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.5467673933823127\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5402177782501235\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5790254835512868\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.3712073972067681\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.6313305774259853\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.2978264872799953\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.532711198227072\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5736352547698373\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.345553313837504\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.570522608825313\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.3723018251752721\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.49912513174093476\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.513016430894912\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.5032902132385277\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.642253902350784\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.4687515569427372\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5913283538475783\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5974179986697143\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.5574860824529195\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.6324610616455235\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.3906705460990968\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.4775449274534982\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5376188620510385\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.2629199062107419\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.5817225565647675\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.48762730561367884\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.6064007162496821\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5894495927646438\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.4640832005259772\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.6077519360622448\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.18304873029621693\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5848289591358373\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5483149255041018\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.335521089108749\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.6379209514663591\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.3805965189716094\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5997487349733539\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5422617362062667\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.37398191567134154\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.5893477036700093\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.2773017207862294\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5440955614013365\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5745166557703728\n",
      "Find parameters for Biodesign A\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.7783856855561462\n",
      "Updated hyperparameters for building: Biodesign Amax_R2:0.7783856855561462: Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.7950872403407889\n",
      "Updated hyperparameters for building: Biodesign Amax_R2:0.7950872403407889: Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.7462449689944162\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7720172074193714\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7787238499600035\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.7859018028015529\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.7824454008152694\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.7991077581247655\n",
      "Updated hyperparameters for building: Biodesign Amax_R2:0.7991077581247655: Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7868843082436731\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.792443560679658\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.7834798379026603\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.7847138591813698\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.767636875254455\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.788613900089811\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7923512052187556\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.7749755106433486\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.7843146461946893\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.7347730366028669\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7774711427976739\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7809718379968211\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.782845511903062\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.774376216752503\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.642739735231018\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7860801700105311\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7827781436286747\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.782918639440678\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.7792533351998814\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.717369475292568\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7745737827159639\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7825540580712912\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.7823870134402277\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.7881150673507094\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.683294846262139\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7873578044807474\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7872199182166131\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.7814746883832921\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.7818220218769595\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.705230763623632\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7814860090554933\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7747903010652248\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.7708881696704238\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.7791971536746115\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.4233140753359045\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7872968205846171\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7794240777178054\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.7962912149219414\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.7744219271450962\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.7740836401532738\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7903897104217321\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7708095097587735\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.7847364214265304\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.7933453949103167\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.7766492227205921\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7806324408025321\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7870012079312318\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.7926349851237727\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.7868781071112517\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.7725581200525249\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7843249405660202\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7887513935739605\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.7781351773360758\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.7802860081323313\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.6687621851360938\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7753148444448248\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7863849739313864\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.7799700880001774\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.784387879514128\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.5815073077536626\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7824126608957762\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7806674823268043\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.7824137069839756\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.7881304861725964\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.5348005450957014\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7862192172845127\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7861023260875769\n",
      "Find parameters for Psychology\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.7809765062746052\n",
      "Updated hyperparameters for building: Psychologymax_R2:0.7809765062746052: Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7941175107216621\n",
      "Updated hyperparameters for building: Psychologymax_R2:0.7941175107216621: Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.6060187520217828\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7881955883092506\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.79838982295102\n",
      "Updated hyperparameters for building: Psychologymax_R2:0.79838982295102: Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.7877620503668215\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.7893598989681512\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.6137260973357993\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7921952543018771\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7810939819569952\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.7936374525876201\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.7944645908916124\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.6278633411004432\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7726252020313316\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7874648378307572\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.7857814438438551\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.7736009300035964\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.6330690844828768\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7836264895293792\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7813565278990431\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.7753764180508481\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.7913727200340047\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.6228534434549811\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.793079378952412\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7879805871206431\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.7865407331380673\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.7939232484394245\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.6128290193600695\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7897664795079644\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7757376254487822\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.7888141557185624\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.7898045001190395\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.5624710446781525\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7809561612276664\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.805383488953384\n",
      "Updated hyperparameters for building: Psychologymax_R2:0.805383488953384: Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.7936242626210435\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.7815301249266204\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.6127956149674236\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7862638344346643\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7828975928439894\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.8024441233704735\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.7824535269176884\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.5961447262849018\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.76408335335125\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7732591479311097\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.7890473578322348\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.7842076063064943\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.5797173621766653\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.773377924920947\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8053831377578076\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.7954276803057495\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.7801678613987785\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.5956958818306273\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7933373512344237\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.789393550720241\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.7852626651225233\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.7928309200541946\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.5935410797408767\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7993622555270692\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7693892233827242\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_squared_error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781969986063668\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.7922581066783203\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.5214027384405966\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7720527967119502\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7932148651561688\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.7929163001547765\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.7861387657989373\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.5330122066314026\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7800525993814914\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7919287306642234\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.7715733059623249\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.7939752826433861\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.5744872430659976\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.7908960728419472\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.7857926025949907\n",
      "Find parameters for Biodesign B\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.8969034661047056\n",
      "Updated hyperparameters for building: Biodesign Bmax_R2:0.8969034661047056: Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.8960674804655029\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.8853755843469601\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9003228738630787\n",
      "Updated hyperparameters for building: Biodesign Bmax_R2:0.9003228738630787: Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9010579299980573\n",
      "Updated hyperparameters for building: Biodesign Bmax_R2:0.9010579299980573: Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.9002818016478014\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.8989961235302139\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.8901724288598121\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9027059921812817\n",
      "Updated hyperparameters for building: Biodesign Bmax_R2:0.9027059921812817: Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8931320577316457\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.9007291913444289\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.894787556136996\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.8944542902431012\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8973092147312218\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8958079453225596\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.9062804690980405\n",
      "Updated hyperparameters for building: Biodesign Bmax_R2:0.9062804690980405: Activation Fn: elu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.896699277744857\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.8774399097117825\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9015023495064899\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9014538871046525\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.8897712276890171\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.9009455564343242\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.891992607065008\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8980634874569878\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9051541153618222\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.8967950987600005\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.8959362214851025\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.8930026042524826\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8999357796571192\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8985332294382419\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.8965041972568891\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.9026454431070765\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.858043869718877\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9023210646215001\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9026313014079904\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.9017884144805639\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.9000442435511367\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.8903519255201455\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.901158533171938\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8936207205092201\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.9022032897903012\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.898023395218225\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8959259455106108\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9084483273562799\n",
      "Updated hyperparameters for building: Biodesign Bmax_R2:0.9084483273562799: Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9008497427257071\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.9103963659429094\n",
      "Updated hyperparameters for building: Biodesign Bmax_R2:0.9103963659429094: Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.9016169280200741\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.8876320841579647\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.904541378408682\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9025849152171704\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.9047989401850973\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.9016281258328451\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.8918838617708913\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9058891281535977\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9026944490957534\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.9041423110798054\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.8936140317161803\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.9024841350714596\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9006711930159436\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9030414436206212\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.9024295067537867\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.8997024243367054\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.8804529255762017\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9035690842588477\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9015469285251825\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.9041117267713005\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.9030266752276035\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.8865744491310809\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9034543476962319\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.8992769264483074\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.8990743066192751\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.9028018458944718\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.8895648475737875\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9019424507667786\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9039620984258872\n",
      "Find parameters for Noble Library\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.5261497865216929\n",
      "Updated hyperparameters for building: Noble Librarymax_R2:0.5261497865216929: Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.5499997530665867\n",
      "Updated hyperparameters for building: Noble Librarymax_R2:0.5499997530665867: Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.4506155065687334\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5232695304342727\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5469169062010975\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.5277064103157831\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.5640653030293168\n",
      "Updated hyperparameters for building: Noble Librarymax_R2:0.5640653030293168: Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.4105289514027224\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5287015829629726\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.533574329235607\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.5031055418117303\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.5350768538991867\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.4399218250874296\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5495899893894982\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5360994784217203\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.4909175801889979\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.5614400157992266\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.3460846654424673\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5443545237565401\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5678658678578159\n",
      "Updated hyperparameters for building: Noble Librarymax_R2:0.5678658678578159: Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.5032436690183714\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.5723360796055186\n",
      "Updated hyperparameters for building: Noble Librarymax_R2:0.5723360796055186: Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38504779593081095\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5608894006381275\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5545996274075407\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.5155834137512498\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.5595782394244632\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.2371691637416785\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5378892397269157\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5330477372792858\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.5307582416857133\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.560168462382227\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.31050066563838075\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5415319451413416\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5485107585279557\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.5251887821483467\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.5334962988064378\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.2700358029403358\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.542114251658433\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5327219048746337\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.49524031873883945\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.5579691220251354\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.3849622104207442\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5234844467992679\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5331852657703771\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.5352115560029476\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.5650565702431924\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.36868383284189754\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5423633725025259\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5565554382099122\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.5404138292769962\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.560274795013302\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.40576706969887266\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5352336668577642\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5358868276281087\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.5390281511886219\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.5549750489231912\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.44526660182610966\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5362726525321129\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5262303966478661\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.5349525811515612\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.560070028536652\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.20679665895464605\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5346439932832441\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5246345364408671\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.5236161986912491\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.5413804975632408\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.28078954954249824\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5441657760809964\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.5083246205671875\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.5043014859903849\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.561502331403576\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.3598987163154074\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.5313625091589103\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.508595492274551\n",
      "Find parameters for ISTB 4\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.9046997222928527\n",
      "Updated hyperparameters for building: ISTB 4max_R2:0.9046997222928527: Activation Fn: relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.9105592908105422\n",
      "Updated hyperparameters for building: ISTB 4max_R2:0.9105592908105422: Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.8977911763103598\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9057942694545416\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9093550411231798\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.9067053642707174\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.8974836109611906\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8709306610447851\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.903132504540116\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9055979115775217\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.9042144927428792\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.9076631191154226\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.8679667175303122\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8994777009748056\n",
      "Results for hyperparameters:Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9109068131103799\n",
      "Updated hyperparameters for building: ISTB 4max_R2:0.9109068131103799: Activation Fn: relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.9093396880304178\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.9064021119990109\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.5761834928714388\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9072072081640771\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9043380948066554\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.9077555197172584\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.9040848823055395\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.5359867831204621\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9048436570354965\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.904818821147172\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.9025561206652337\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.9022488220990318\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.33328033921948463\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8906061443188361\n",
      "Results for hyperparameters:Activation Fn: elu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9043452452363815\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.9104119828720668\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.9075934517776434\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.5877171141798183\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.8998347521919163\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9019769684588055\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.8956440178025696\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.9013584980083893\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.7308640512834568\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9068356029970981\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9054005359578238\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.899012061575345\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.9065559805315824\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.08770150631854501\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9015788274309211\n",
      "Results for hyperparameters:Activation Fn: selu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9043426067905637\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.9124276402287153\n",
      "Updated hyperparameters for building: ISTB 4max_R2:0.9124276402287153: Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_squared_error\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.8988620602281109\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.8450063375788098\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9036495739073549\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9083612453242313\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.9063235326928163\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_error\n",
      "0.8958212995659685\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.7519500051978509\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9021687592734969\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9027045808927403\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.8962238671956464\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.9040608514060435\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "0.9145568016719716\n",
      "Updated hyperparameters for building: ISTB 4max_R2:0.9145568016719716: Activation Fn: leaky_relu #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.902754026377719\n",
      "Results for hyperparameters:Activation Fn: leaky_relu #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9031008475702326\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_squared_error\n",
      "0.9052242357743491\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_error\n",
      "0.90342174653415\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: mean_absolute_percentage_error\n",
      "0.3868906376027115\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9016376499689681\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 1 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9091682476667855\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_squared_error\n",
      "0.9034454899423867\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9020997092241484\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: mean_absolute_percentage_error\n",
      "0.10643880857935417\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.902317527209268\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 3 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9059865880629203\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_squared_error\n",
      "0.9055843517194493\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_error\n",
      "0.9019578860449589\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: mean_absolute_percentage_error\n",
      "-0.0033494428827305356\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss at 0x7f2014467e60>\n",
      "0.9009390312770589\n",
      "Results for hyperparameters:Activation Fn: tanh #hidden_layers: 5 loss function: <function huber_loss_mean at 0x7f1fa8389320>\n",
      "0.9033363597763794\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bldgname</th>\n",
       "      <th>R2_score_bigdata_best</th>\n",
       "      <th>R2_score_limiteddata_best</th>\n",
       "      <th>Activation Function</th>\n",
       "      <th>No of hidden layers</th>\n",
       "      <th>Loss function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Goldwater</td>\n",
       "      <td>0.941795</td>\n",
       "      <td>0.932904</td>\n",
       "      <td>elu</td>\n",
       "      <td>1</td>\n",
       "      <td>mean_squared_error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bulldog Hall</td>\n",
       "      <td>0.822449</td>\n",
       "      <td>0.52737</td>\n",
       "      <td>selu</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;function huber_loss at 0x7f2014467e60&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISTB 2</td>\n",
       "      <td>0.940297</td>\n",
       "      <td>0.877108</td>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;function huber_loss at 0x7f2014467e60&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Psychology North</td>\n",
       "      <td>0.833397</td>\n",
       "      <td>0.750683</td>\n",
       "      <td>selu</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;function huber_loss at 0x7f2014467e60&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schwada COB</td>\n",
       "      <td>0.862224</td>\n",
       "      <td>0.849587</td>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>mean_squared_error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Biodesign C</td>\n",
       "      <td>0.715214</td>\n",
       "      <td>0.669161</td>\n",
       "      <td>elu</td>\n",
       "      <td>5</td>\n",
       "      <td>mean_absolute_error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Biodesign A</td>\n",
       "      <td>0.915566</td>\n",
       "      <td>0.799108</td>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Psychology</td>\n",
       "      <td>0.907348</td>\n",
       "      <td>0.805383</td>\n",
       "      <td>selu</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;function huber_loss_mean at 0x7f1fa8389320&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Biodesign B</td>\n",
       "      <td>0.962164</td>\n",
       "      <td>0.910396</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>1</td>\n",
       "      <td>mean_squared_error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Noble Library</td>\n",
       "      <td>0.785088</td>\n",
       "      <td>0.572336</td>\n",
       "      <td>elu</td>\n",
       "      <td>3</td>\n",
       "      <td>mean_absolute_error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>0.962567</td>\n",
       "      <td>0.914557</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>5</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bldgname R2_score_bigdata_best R2_score_limiteddata_best  \\\n",
       "0          Goldwater              0.941795                  0.932904   \n",
       "1       Bulldog Hall              0.822449                   0.52737   \n",
       "2             ISTB 2              0.940297                  0.877108   \n",
       "3   Psychology North              0.833397                  0.750683   \n",
       "4        Schwada COB              0.862224                  0.849587   \n",
       "5        Biodesign C              0.715214                  0.669161   \n",
       "6        Biodesign A              0.915566                  0.799108   \n",
       "7         Psychology              0.907348                  0.805383   \n",
       "8        Biodesign B              0.962164                  0.910396   \n",
       "9      Noble Library              0.785088                  0.572336   \n",
       "10            ISTB 4              0.962567                  0.914557   \n",
       "\n",
       "   Activation Function No of hidden layers  \\\n",
       "0                  elu                   1   \n",
       "1                 selu                   5   \n",
       "2                 relu                   5   \n",
       "3                 selu                   1   \n",
       "4                 relu                   5   \n",
       "5                  elu                   5   \n",
       "6                 relu                   3   \n",
       "7                 selu                   1   \n",
       "8           leaky_relu                   1   \n",
       "9                  elu                   3   \n",
       "10          leaky_relu                   5   \n",
       "\n",
       "                                   Loss function  \n",
       "0                             mean_squared_error  \n",
       "1        <function huber_loss at 0x7f2014467e60>  \n",
       "2        <function huber_loss at 0x7f2014467e60>  \n",
       "3        <function huber_loss at 0x7f2014467e60>  \n",
       "4                             mean_squared_error  \n",
       "5                            mean_absolute_error  \n",
       "6                 mean_absolute_percentage_error  \n",
       "7   <function huber_loss_mean at 0x7f1fa8389320>  \n",
       "8                             mean_squared_error  \n",
       "9                            mean_absolute_error  \n",
       "10                mean_absolute_percentage_error  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# eval_func = []\n",
    "# max_R2 = -inf\n",
    "# for func in activation_functions:\n",
    "#     eval_func_layers = []\n",
    "#     for hl in no_hidden_layers:\n",
    "#         eval_func_loss = []\n",
    "#         for loss in loss_functions:\n",
    "#             model = define_model(func,hl,loss)\n",
    "#             history = model.fit(X_train, Y_train, batch_size=128, epochs=150,  validation_split=0.2, verbose=0)\n",
    "#             RMSE, R2 = evaluate(base_model, X_test, Y_test)\n",
    "#             RMSE_base_model, R2_base_model = evaluate(base_model, X_limited_test,Y_limited_test)\n",
    "#             eval_func_loss.append(R2)\n",
    "#         eval_func_layers.append(eval_func_loss)\n",
    "#     eval_func.append(eval_func_layers)\n",
    "# print(eval_func)   \n",
    "# tab = pd.DataFrame(eval_func, activation_functions, no_hidden_layers_headings,loss_functions_headings)\n",
    "# print(tab)\n",
    "\n",
    "def tune_multiple_buildings():\n",
    "    activation_functions = ['relu','elu','selu','leaky_relu','tanh']\n",
    "    no_hidden_layers = [1,3,5]\n",
    "    loss_functions = ['mean_squared_error','mean_absolute_error','mean_absolute_percentage_error',huber_loss,huber_loss_mean]\n",
    "#     loss_functions_headings = ['mean_squared_error','mean_absolute_error','mean_absolute_percentage_error','huber_loss','huber_loss_mean']\n",
    "    ### Create dataframe and add building names ###\n",
    "    rf_optimal_model = pd.DataFrame(columns = {\"bldgname\", \"R2_score_bigdata_best\",\"R2_score_limiteddata_best\", 'Activation Function','No of hidden layers', 'Loss function' })\n",
    "    for i in range(len(Bldg_Lim)):\n",
    "        rf_optimal_model = rf_optimal_model.append({'bldgname': Bldg_Lim[i]['bldgname'].unique()[0]}, ignore_index=True)\n",
    "    rf_optimal_model.fillna(5)\n",
    "    ### Train over all hyperparameters over all buildings ###\n",
    "    for i in range(len(Bldg_Lim)):\n",
    "        max = 0\n",
    "        # drop na values if in dataframe\n",
    "        if (Bldg_Lim[i].isnull().values.any() == True):\n",
    "            Bldg_Lim[i] = Bldg_Lim[i].dropna()\n",
    "        building_name = Bldg_Lim[i]['bldgname'][0] \n",
    "        print(\"Find parameters for \"+ building_name)\n",
    "        optimal_hyperparameters=[]\n",
    "        # Limited Data\n",
    "        X_limited,Y_limited = prepare_data(Bldg_Lim[i])\n",
    "        X_limited_train, X_limited_test, Y_limited_train,Y_limited_test = train_test_split(X_limited,Y_limited , test_size=0.1, random_state=20)\n",
    "        #Big Data\n",
    "        X,Y = prepare_data(Bldg_Big[i])\n",
    "        X_train, X_test, Y_train,Y_test = train_test_split(X, Y, test_size=0.2, random_state=20)\n",
    "        for func in activation_functions:\n",
    "            for hl in no_hidden_layers:\n",
    "                for loss in loss_functions:\n",
    "                    print(\"Results for hyperparameters:Activation Fn: \"+ func+ \" #hidden_layers: \"+ str(hl) + \" loss function: \"+ str(loss))\n",
    "                    model = define_model(func,hl,loss)\n",
    "                    history = model.fit(X_train, Y_train, batch_size=128, epochs=150,  validation_split=0.2, verbose=0)\n",
    "                    RMSE, R2 = evaluate(model, X_test, Y_test)\n",
    "                    RMSE_base_model, R2_base_model = evaluate(model, X_limited_test,Y_limited_test)\n",
    "                    print(R2_base_model)\n",
    "                    if(R2_base_model>max):\n",
    "                        max = R2_base_model\n",
    "                        print(\"Updated hyperparameters for building: \"+ building_name +\"max_R2:\"+str(max)+\": Activation Fn: \"+ str(func)+ \" #hidden_layers: \"+ str(hl) + \" loss function: \"+ str(loss))\n",
    "                        rf_optimal_model[\"R2_score_bigdata_best\"][i]=R2\n",
    "                        rf_optimal_model[\"R2_score_limiteddata_best\"][i]=R2_base_model\n",
    "                        rf_optimal_model[\"Activation Function\"][i]=func\n",
    "                        rf_optimal_model[\"No of hidden layers\"][i]=hl\n",
    "                        rf_optimal_model[\"Loss function\"][i]=loss\n",
    "    rf_optimal_model = rf_optimal_model[[\"bldgname\", \"R2_score_bigdata_best\",\"R2_score_limiteddata_best\", 'Activation Function','No of hidden layers', 'Loss function']]\n",
    "    return rf_optimal_model\n",
    "optimal_model_buildings = tune_multiple_buildings()\n",
    "display(optimal_model_buildings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba3fec",
   "metadata": {
    "id": "f0ba3fec"
   },
   "source": [
    "## 5.4 Train Model with Optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e15c0f49",
   "metadata": {
    "id": "e15c0f49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_306 (Dense)            (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_307 (Dense)            (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_308 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_309 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_310 (Dense)            (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_311 (Dense)            (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 383\n",
      "Trainable params: 383\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = define_model('relu',5,'mae')\n",
    "history = base_model.fit(X_train, Y_train, batch_size=128, epochs=100, verbose=0, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d9d4ee",
   "metadata": {
    "id": "07d9d4ee"
   },
   "source": [
    "## 5.5 Evaluate Base Model with Big Dataset and Limited Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eff03f75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "eff03f75",
    "outputId": "f540dfb5-c8d8-415b-bb4c-af440b86cfa2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9744392032899065\n",
      "0.9225195443826308\n"
     ]
    }
   ],
   "source": [
    "plot_curve(history)\n",
    "RMSE, R2 = evaluate(base_model, X_test, Y_test)\n",
    "RMSE_base_model, R2_base_model = evaluate(base_model, X_limited_test,Y_limited_test)\n",
    "print(R2)\n",
    "print(R2_base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9594740b",
   "metadata": {
    "id": "9594740b"
   },
   "source": [
    "## 5.6 Transfer features and Fine Tune Base Model on Limited Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cf537f55",
   "metadata": {
    "id": "cf537f55"
   },
   "outputs": [],
   "source": [
    "\n",
    "fine_tuned_model = fine_tune(base_model,huber_loss)\n",
    "# X_limited,Y_limited = prepare_data(envimet)\n",
    "history = fine_tuned_model.fit(X_limited_train,Y_limited_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6e6636",
   "metadata": {
    "id": "dc6e6636"
   },
   "source": [
    "## 5.7 Evaluate Fine-tuned Model on Limited Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e11abc6f",
   "metadata": {
    "id": "e11abc6f",
    "outputId": "5a62891e-168b-468e-940e-ab1eb9fe8c36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9655515485952206\n"
     ]
    }
   ],
   "source": [
    "RMSE_fine_tune ,R2_fine_tune= evaluate(fine_tuned_model,X_limited_test,Y_limited_test)\n",
    "print(R2_fine_tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c13800e",
   "metadata": {
    "id": "1c13800e"
   },
   "source": [
    "## 5.8 Implement for all Buildings and report score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5896140a",
   "metadata": {
    "id": "5896140a",
    "outputId": "0b3d7066-68d7-41a2-a373-7f4d15fa0e08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model for Goldwater\n",
      "Train model for Goldwater Big Data\n",
      "Train model for Goldwater Limited Data\n",
      "Train model for Bulldog Hall\n",
      "Train model for Bulldog Hall Big Data\n",
      "Train model for Bulldog Hall Limited Data\n",
      "Train model for ISTB 2\n",
      "Train model for ISTB 2 Big Data\n",
      "Train model for ISTB 2 Limited Data\n",
      "Train model for Psychology North\n",
      "Train model for Psychology North Big Data\n",
      "Train model for Psychology North Limited Data\n",
      "Train model for Schwada COB\n",
      "Train model for Schwada COB Big Data\n",
      "Train model for Schwada COB Limited Data\n",
      "Train model for Biodesign C\n",
      "Train model for Biodesign C Big Data\n",
      "Train model for Biodesign C Limited Data\n",
      "Train model for Biodesign A\n",
      "Train model for Biodesign A Big Data\n",
      "Train model for Biodesign A Limited Data\n",
      "Train model for Psychology\n",
      "Train model for Psychology Big Data\n",
      "Train model for Psychology Limited Data\n",
      "Train model for Biodesign B\n",
      "Train model for Biodesign B Big Data\n",
      "Train model for Biodesign B Limited Data\n",
      "Train model for Noble Library\n",
      "Train model for Noble Library Big Data\n",
      "Train model for Noble Library Limited Data\n",
      "Train model for ISTB 4\n",
      "Train model for ISTB 4 Big Data\n",
      "Train model for ISTB 4 Limited Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bldgname</th>\n",
       "      <th>R2_score_base_model</th>\n",
       "      <th>RMSE_score_base_model</th>\n",
       "      <th>R2_score_finetuned_model</th>\n",
       "      <th>RMSE_score_finetuned_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Goldwater</td>\n",
       "      <td>0.931122</td>\n",
       "      <td>0.27306</td>\n",
       "      <td>0.967939</td>\n",
       "      <td>0.186298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bulldog Hall</td>\n",
       "      <td>0.522527</td>\n",
       "      <td>0.707748</td>\n",
       "      <td>0.599835</td>\n",
       "      <td>0.647923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISTB 2</td>\n",
       "      <td>0.854834</td>\n",
       "      <td>0.394397</td>\n",
       "      <td>0.91791</td>\n",
       "      <td>0.296584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Psychology North</td>\n",
       "      <td>0.686708</td>\n",
       "      <td>0.55346</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>0.374076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schwada COB</td>\n",
       "      <td>0.843894</td>\n",
       "      <td>0.42265</td>\n",
       "      <td>0.9024</td>\n",
       "      <td>0.334192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Biodesign C</td>\n",
       "      <td>0.47775</td>\n",
       "      <td>0.73282</td>\n",
       "      <td>0.836185</td>\n",
       "      <td>0.410425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Biodesign A</td>\n",
       "      <td>0.787245</td>\n",
       "      <td>0.463889</td>\n",
       "      <td>0.869345</td>\n",
       "      <td>0.363527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Psychology</td>\n",
       "      <td>0.792377</td>\n",
       "      <td>0.445067</td>\n",
       "      <td>0.901481</td>\n",
       "      <td>0.306582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Biodesign B</td>\n",
       "      <td>0.885236</td>\n",
       "      <td>0.35123</td>\n",
       "      <td>0.954089</td>\n",
       "      <td>0.22215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Noble Library</td>\n",
       "      <td>0.551427</td>\n",
       "      <td>0.694863</td>\n",
       "      <td>0.741218</td>\n",
       "      <td>0.527775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ISTB 4</td>\n",
       "      <td>0.898862</td>\n",
       "      <td>0.302675</td>\n",
       "      <td>0.943207</td>\n",
       "      <td>0.226812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bldgname R2_score_base_model RMSE_score_base_model  \\\n",
       "0          Goldwater            0.931122               0.27306   \n",
       "1       Bulldog Hall            0.522527              0.707748   \n",
       "2             ISTB 2            0.854834              0.394397   \n",
       "3   Psychology North            0.686708               0.55346   \n",
       "4        Schwada COB            0.843894               0.42265   \n",
       "5        Biodesign C             0.47775               0.73282   \n",
       "6        Biodesign A            0.787245              0.463889   \n",
       "7         Psychology            0.792377              0.445067   \n",
       "8        Biodesign B            0.885236               0.35123   \n",
       "9      Noble Library            0.551427              0.694863   \n",
       "10            ISTB 4            0.898862              0.302675   \n",
       "\n",
       "   R2_score_finetuned_model RMSE_score_finetuned_model  \n",
       "0                  0.967939                   0.186298  \n",
       "1                  0.599835                   0.647923  \n",
       "2                   0.91791                   0.296584  \n",
       "3                  0.856881                   0.374076  \n",
       "4                    0.9024                   0.334192  \n",
       "5                  0.836185                   0.410425  \n",
       "6                  0.869345                   0.363527  \n",
       "7                  0.901481                   0.306582  \n",
       "8                  0.954089                    0.22215  \n",
       "9                  0.741218                   0.527775  \n",
       "10                 0.943207                   0.226812  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "def model_multiple():\n",
    "    ### Create dataframe and add building names ###\n",
    "    rf_bld_scores = pd.DataFrame(columns = {\"bldgname\", \"R2_score_base_model\",\"RMSE_score_base_model\", \"R2_score_finetuned_model\",\"RMSE_score_finetuned_model\"})\n",
    "    for i in range(len(Bldg_Lim)):\n",
    "        rf_bld_scores = rf_bld_scores.append({'bldgname': Bldg_Lim[i]['bldgname'].unique()[0]}, ignore_index=True)\n",
    "    rf_bld_scores.fillna(5)\n",
    "    ### Append scores to all buildings ###\n",
    "    for i in range(len(Bldg_Lim)):\n",
    "        # drop na values if in dataframe\n",
    "        if (Bldg_Lim[i].isnull().values.any() == True):\n",
    "            Bldg_Lim[i] = Bldg_Lim[i].dropna()\n",
    "        building_name = Bldg_Lim[i]['bldgname'][0] \n",
    "        print(\"Train model for \"+ building_name )\n",
    "        # Limited Data\n",
    "        X_limited,Y_limited = prepare_data(Bldg_Lim[i])\n",
    "        X_limited_train, X_limited_test, Y_limited_train,Y_limited_test = train_test_split(X_limited,Y_limited , test_size=0.1, random_state=20)\n",
    "        #Big Data\n",
    "        X,Y = prepare_data(Bldg_Big[i])\n",
    "        X_train, X_test, Y_train,Y_test = train_test_split(X, Y, test_size=0.2, random_state=20)\n",
    "        base_model = define_model('relu',3, huber_loss_mean)\n",
    "        print(\"Train model for \"+ building_name +\" Big Data\" )\n",
    "        history_base = base_model.fit(X_train, Y_train, batch_size=128, epochs=100, verbose=0, validation_split=0.2)\n",
    "        RMSE, R2 = evaluate(base_model, X_test, Y_test)\n",
    "        RMSE_base_model, R2_base_model = evaluate(base_model, X_limited_test,Y_limited_test)\n",
    "        rf_bld_scores[\"R2_score_base_model\"][i] = R2_base_model\n",
    "        rf_bld_scores[\"RMSE_score_base_model\"][i] = RMSE_base_model   \n",
    "        fine_tuned_model = fine_tune(base_model,huber_loss_mean)\n",
    "        print(\"Train model for \"+ building_name +\" Limited Data\" )\n",
    "        history_fine_tune = fine_tuned_model.fit(X_limited_train,Y_limited_train, epochs=50, verbose=0)\n",
    "        RMSE_fine_tune ,R2_fine_tune= evaluate(fine_tuned_model,X_limited_test,Y_limited_test)\n",
    "        rf_bld_scores[\"R2_score_finetuned_model\"][i] = R2_fine_tune\n",
    "        rf_bld_scores[\"RMSE_score_finetuned_model\"][i] = RMSE_fine_tune\n",
    "        rf_bld_scores= rf_bld_scores[[\"bldgname\", \"R2_score_base_model\",\"RMSE_score_base_model\", \"R2_score_finetuned_model\",\"RMSE_score_finetuned_model\"]]\n",
    "    return rf_bld_scores\n",
    "multiple_bldg_scores = model_multiple()\n",
    "display(multiple_bldg_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2ac823",
   "metadata": {
    "id": "4f2ac823"
   },
   "source": [
    "<!-- Which buildings are we training for? To be decided depending on results  -->\n",
    "<!-- Train for all buildings automatically and report the scores for base_model and fine_tuned_model. -->\n",
    "<!-- What scores is RF reporting? RF reports the R2 score. Add R2 score to evaluators. Create a list for evaluating and then visualise it. Not a great score, needs improvements.  -->\n",
    "<!-- How to visualise the results? Made comparison matrix for now -->\n",
    "<!-- How to improve the results? Experiment with loss function -->\n",
    "<!-- Automate model selection: run over iterations of activation function, number of hidden layers, loss function  -->\n",
    "lr scheduler\n",
    "Change Y to y everywhere(Regression problem)\n",
    "Add functionality to pass building names which we want to model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Micro_Energy_NN_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
