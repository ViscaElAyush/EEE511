{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Micro_Energy_NN_v5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86c60a22",
        "outputId": "15c235e0-39f3-418a-de8b-bc3eef93fe4f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "86c60a22",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1539d50"
      },
      "source": [
        "## Flow of Code:\n",
        "#### 1. Read both datasets, and do data preparation: Scaling, One-hot Encoding\n",
        "#### 2. For limited data, train  model on Temp, Hum, Dsw(4), Shade(4), Encoding input features (find hyperparameters analytically)\n",
        "#### 3. For big data, train model on Temp, Hum, Encoding \n",
        "#### 4. Fine tune weather station model on microclimate data and compare performance\n",
        "#### 5. Work on adding artificial features and dropout on microclimate model"
      ],
      "id": "f1539d50"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c914ba15",
        "outputId": "090fda7a-8485-4bb6-d910-c479d895dbbd"
      },
      "source": [
        "# Load the TensorBoard notebook extension.\n",
        "\n",
        "%reload_ext tensorboard\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.keras import initializers\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.python.keras.optimizer_v2.adam import Adam\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import pickle\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import cm\n",
        "from datetime import datetime\n",
        "import seaborn as sns\n",
        "import tensorboard\n",
        "tensorboard.__version__"
      ],
      "id": "c914ba15",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f803fbe1"
      },
      "source": [
        "class NeuralNetwork():\n",
        "    def __init__(self,activation_type, hidden_layers, loss, kernel_initializer, bias_initializer, data_type,epochs):\n",
        "        self.activation_type = activation_type\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.loss = loss\n",
        "        self.kernel_initializer = kernel_initializer\n",
        "        self.bias_initializer = bias_initializer \n",
        "        self.data_type = data_type\n",
        "        self.epochs = epochs\n",
        "    def huber_loss(y_true, y_pred, clip_delta=1.0):\n",
        "        error = y_true - y_pred\n",
        "        cond  = tf.keras.backend.abs(error) < clip_delta\n",
        "        squared_loss = 0.5 * tf.keras.backend.square(error)\n",
        "        linear_loss  = clip_delta * (tf.keras.backend.abs(error) - 0.5 * clip_delta)\n",
        "        return tf.where(cond, squared_loss, linear_loss)\n",
        "    def huber_loss_mean(y_true, y_pred, clip_delta=1.0):\n",
        "        return tf.keras.backend.mean(huber_loss(y_true, y_pred, clip_delta))\n",
        "    def prepare_data(self, dataset, func):\n",
        "        Y = dataset['CHWTON/SQFT']\n",
        "        if self.data_type == 'WeatherStation'  and (func == 'test' or func == 'train'):\n",
        "            X = dataset[['Air Temp', 'Abs Hum']]\n",
        "        if self.data_type == 'Microclimate' and func == 'train':\n",
        "            X = dataset[['Air Temp', \n",
        "                         'Abs Hum', \n",
        "                         'DSW North', \n",
        "                         'DSW South', \n",
        "                         'DSW East', \n",
        "                         'DSW West', \n",
        "                         'Shade North', \n",
        "                         'Shade East', \n",
        "                         'Shade West',\n",
        "                         'Shade South']]\n",
        "        if self.data_type == 'Microclimate' and func == 'test':\n",
        "            X = dataset[['Air Temp', \n",
        "                         'Abs Hum']]\n",
        "        X_bldg_name = dataset[['bldgname']]\n",
        "        Y = Y.values.reshape(-1, 1)\n",
        "        #create one-hot encoding for all buildings\n",
        "        one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "        one_hot_encoder.fit(X_bldg_name)\n",
        "        X_bldg_name_encoded = one_hot_encoder.transform(X_bldg_name)\n",
        "        X_bldg_name_encoded = pd.DataFrame(data=X_bldg_name_encoded, columns=one_hot_encoder.categories_)\n",
        "        X_bldg_name_encoded = np.asarray(X_bldg_name_encoded).astype('float32')\n",
        "        # Normalize input and target values\n",
        "        scaler1 = StandardScaler()\n",
        "        X_scaled = scaler1.fit_transform(X)\n",
        "        scaler2 = StandardScaler()\n",
        "        Y_scaled = scaler2.fit_transform(Y)\n",
        "        # add categorical to numeric data\n",
        "        X_final = np.concatenate((X_bldg_name_encoded, X_scaled), axis =1)\n",
        "        X_final = np.asarray(X_final).astype('float32')\n",
        "        Y_scaled = np.asarray(Y_scaled).astype('float32')\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_final, Y_scaled, \n",
        "                                                           test_size=0.2, \n",
        "                                                           random_state=20)\n",
        "        return X_train, X_test, y_train, y_test\n",
        "    def define_model(self):\n",
        "        if self.data_type == 'WeatherStation' :\n",
        "            model = Sequential()\n",
        "            if self.activation_type == 'leaky_relu':\n",
        "                model.add(Dense(20, \n",
        "                                input_dim=13, \n",
        "                                kernel_initializer=self.kernel_initializer, \n",
        "                                bias_initializer=self.bias_initializer, \n",
        "                                activation= self.activation_type))\n",
        "                for i in range(0,(self.hidden_layers-2)):\n",
        "                    model.add(Dense(30, activation = self.activation_type))\n",
        "                model.add(Dense(20, activation = self.activation_type))\n",
        "                model.add(Dense(1, activation = 'linear'))\n",
        "            else:\n",
        "                model.add(Dense(30, \n",
        "                                input_dim=13, \n",
        "                                kernel_initializer=self.kernel_initializer, \n",
        "                                bias_initializer=self.bias_initializer, \n",
        "                                activation= self.activation_type))\n",
        "                for i in range(0,(self.hidden_layers-2)):\n",
        "                    model.add(Dense(40, activation = self.activation_type))\n",
        "                model.add(Dense(20, activation = self.activation_type))\n",
        "                model.add(Dense(1, activation = 'linear'))\n",
        "            \n",
        "            \n",
        "        if self.data_type == 'Microclimate':\n",
        "            model = Sequential()\n",
        "            if self.activation_type == 'leaky_relu':\n",
        "                model.add(Dense(30, \n",
        "                                input_dim=21, \n",
        "                                kernel_initializer=self.kernel_initializer, \n",
        "                                bias_initializer=self.bias_initializer, \n",
        "                                activation= self.activation_type))\n",
        "                for i in range(0,(self.hidden_layers-2)):\n",
        "                    model.add(Dense(40, activation = self.activation_type))\n",
        "                model.add(Dense(20, activation = self.activation_type))\n",
        "                model.add(Dense(1, activation = 'linear'))\n",
        "            else:\n",
        "                model.add(Dense(30, \n",
        "                                input_dim=21, \n",
        "                                kernel_initializer=self.kernel_initializer, \n",
        "                                bias_initializer=self.bias_initializer, \n",
        "                                activation= self.activation_type))\n",
        "                for i in range(0,(self.hidden_layers-2)):\n",
        "                    model.add(Dense(40, activation = self.activation_type))\n",
        "                model.add(Dense(20, activation = self.activation_type))\n",
        "                model.add(Dense(1, activation = 'linear'))\n",
        "        model.compile( loss = self.loss, \n",
        "                      optimizer = 'adam')\n",
        "        model.summary()\n",
        "        return model\n",
        "    def train(self, dataset):\n",
        "        X_train, X_test, y_train, y_test = self.prepare_data(dataset,'train')\n",
        "        self.model = self.define_model()\n",
        "        # Define the Keras TensorBoard callback.\n",
        "        logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "        self.history = self.model.fit(X_train,y_train, \n",
        "                            batch_size=128, \n",
        "                            epochs=self.epochs, \n",
        "                            verbose=0, \n",
        "                            validation_split=0.2, \n",
        "                            callbacks=[tensorboard_callback])\n",
        "    def fine_tune(self, dataset,alpha=0.001):\n",
        "        self.model.trainable = True\n",
        "        fine_tune_at = 2\n",
        "        for layer in self.model.layers[:fine_tune_at]:\n",
        "            layer.trainable =  False\n",
        "        opt= Adam(learning_rate=alpha)\n",
        "        self.model.compile(loss=self.loss, \n",
        "                           optimizer=opt)\n",
        "        X_train, X_test, y_train, y_test = self.prepare_data(dataset,'test')\n",
        "        # Define the Keras TensorBoard callback.\n",
        "        logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "        self.history = self.model.fit(X_train,y_train, \n",
        "                            batch_size=128, \n",
        "                            epochs=self.epochs, \n",
        "                            verbose=0, \n",
        "                            validation_split=0.2, \n",
        "                            callbacks=[tensorboard_callback])\n",
        "        \n",
        "        \n",
        "    def plot_curve(self):\n",
        "        plt.plot(self.history.history['loss'])\n",
        "        plt.plot(self.history.history['val_loss'])\n",
        "        plt.title('model loss')\n",
        "        plt.ylabel('loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'validation'], loc='upper left')\n",
        "        plt.show()\n",
        "    def evaluate(self, dataset, data_type ):\n",
        "        call_type = 'test'\n",
        "        if data_type == self.data_type:\n",
        "            call_type = 'train'\n",
        "        _, X_test, _, y_test = self.prepare_data(dataset,call_type)\n",
        "        Y_preds = self.model.predict(X_test)\n",
        "        RMSE = np.sqrt(metrics.mean_squared_error(y_test, Y_preds))\n",
        "        R2_score = metrics.r2_score(y_test, Y_preds)\n",
        "        print(\"The RMSE score for test dataset of \"+ data_type +\" is:\", RMSE)\n",
        "        print(\"The R2 score for test dataset of \"+ data_type +\" is:\", R2_score)\n",
        "        return RMSE,R2_score\n",
        "        \n",
        "                "
      ],
      "id": "f803fbe1",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9b62c44",
        "outputId": "9dd990c6-d5a6-4024-ff1d-ce231e9a76fe"
      },
      "source": [
        "MicroclimateData = pd.read_csv('/content/drive/Shareddrives/Microclimate-Building Energy/Data/microclimate_model/Combined/all_buildings_limited.csv')\n",
        "WeatherStationData = pd.read_csv('/content/drive/Shareddrives/Microclimate-Building Energy/Data/NN_big_data/Combined/all_buildings_big.csv')\n",
        "if __name__ == \"__main__\":\n",
        "    # Train microclimate Model\n",
        "    MicroclimateModel = NeuralNetwork('relu',4, 'huber_loss', 'he_normal','he_normal', 'Microclimate', 200)\n",
        "    MicroclimateModel.train(MicroclimateData)\n",
        "    _,_ = MicroclimateModel.evaluate(MicroclimateData, 'Microclimate')\n",
        "    \n",
        "    _,xTest,_,yTest = MicroclimateModel.prepare_data(MicroclimateData,'train')\n",
        "    yPred = MicroclimateModel.model.predict(xTest)\n",
        "    \n",
        "    \n"
      ],
      "id": "c9b62c44",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_70 (Dense)             (None, 30)                660       \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 40)                1240      \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 40)                1640      \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 20)                820       \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 4,381\n",
            "Trainable params: 4,381\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "The RMSE score for test dataset of Microclimateis: 0.13632365\n",
            "The R2 score for test dataset of Microclimateis: 0.9808207914866267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "YPYi3HzcLwss",
        "outputId": "b6a84ea5-ca29-4ea5-cd04-6143f4006124"
      },
      "source": [
        "    y_tes = [x[0] for x in yTest]    \n",
        "    y_pre = [x[0] for x in yPred]\n",
        "    ModelPred = pd.DataFrame({'Actual CHWTON':y_tes, 'Predicted CHWTON':y_pre})\n",
        "    ModelPred"
      ],
      "id": "YPYi3HzcLwss",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual CHWTON</th>\n",
              "      <th>Predicted CHWTON</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.031620</td>\n",
              "      <td>-1.103264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.685585</td>\n",
              "      <td>1.559486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.434169</td>\n",
              "      <td>1.219953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.121287</td>\n",
              "      <td>1.256245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.741267</td>\n",
              "      <td>0.856180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1913</th>\n",
              "      <td>-0.843508</td>\n",
              "      <td>-0.863981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1914</th>\n",
              "      <td>1.545410</td>\n",
              "      <td>1.773315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1915</th>\n",
              "      <td>1.882579</td>\n",
              "      <td>2.260026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1916</th>\n",
              "      <td>1.285109</td>\n",
              "      <td>1.196050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1917</th>\n",
              "      <td>-0.152536</td>\n",
              "      <td>-0.124062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1918 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Actual CHWTON  Predicted CHWTON\n",
              "0         -1.031620         -1.103264\n",
              "1          1.685585          1.559486\n",
              "2          1.434169          1.219953\n",
              "3          1.121287          1.256245\n",
              "4          0.741267          0.856180\n",
              "...             ...               ...\n",
              "1913      -0.843508         -0.863981\n",
              "1914       1.545410          1.773315\n",
              "1915       1.882579          2.260026\n",
              "1916       1.285109          1.196050\n",
              "1917      -0.152536         -0.124062\n",
              "\n",
              "[1918 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6744b60c",
        "outputId": "03271e7f-5cd9-4d14-bcd2-4014a5c76127"
      },
      "source": [
        "# Train Weather Station Model\n",
        "WeatherStationModel = NeuralNetwork('relu',4, 'huber_loss', 'he_normal','he_normal', 'WeatherStation', 100)\n",
        "WeatherStationModel.train(WeatherStationData)\n",
        "_,_ = WeatherStationModel.evaluate(MicroclimateData, 'Microclimate')\n"
      ],
      "id": "6744b60c",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_75 (Dense)             (None, 30)                420       \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 40)                1240      \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 40)                1640      \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 20)                820       \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 4,141\n",
            "Trainable params: 4,141\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "The RMSE score for test dataset of Microclimateis: 0.5034203\n",
            "The R2 score for test dataset of Microclimateis: 0.7384530296274439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00f1e303",
        "outputId": "c378e6af-0397-4ac0-ab84-c7fd0708f758"
      },
      "source": [
        "# Fine Tune and compare results\n",
        "l_rates = [0.001,0.00125,0.0015,0.00175,0.002,0.003,0.01]\n",
        "R2_max=0\n",
        "RMSE_min=1\n",
        "lr=0\n",
        "for a in l_rates:\n",
        "  print(\"For learning rate :\"+str(a))\n",
        "  WeatherStationModel.fine_tune(MicroclimateData,alpha=a)\n",
        "  RMSE_fine_tune,R2_fine_tune = WeatherStationModel.evaluate(MicroclimateData, 'Microclimate')\n",
        "  if R2_fine_tune>R2_max and RMSE_fine_tune<RMSE_min:\n",
        "    lr=a\n",
        "    R2_max=R2_fine_tune\n",
        "    RMSE_min=RMSE_fine_tune\n",
        "print(\"For final learning rate :\"+str(lr))\n",
        "#MicroClimate Data\n",
        "print(\"The RMSE score for test dataset of Microclimate is:\", RMSE_min)\n",
        "print(\"The R2 score for test dataset of Microclimate is:\", R2_max)\n",
        "#Weather Data\n",
        "Rm,R2=WeatherStationModel.evaluate(WeatherStationData, 'Weatherstation')\n",
        "\n"
      ],
      "id": "00f1e303",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For learning rate :0.001\n",
            "The RMSE score for test dataset of Microclimateis: 0.14760561\n",
            "The R2 score for test dataset of Microclimateis: 0.9775149409672151\n",
            "For learning rate :0.00125\n",
            "The RMSE score for test dataset of Microclimateis: 0.14565828\n",
            "The R2 score for test dataset of Microclimateis: 0.9781043068730914\n",
            "For learning rate :0.0015\n",
            "The RMSE score for test dataset of Microclimateis: 0.14662717\n",
            "The R2 score for test dataset of Microclimateis: 0.9778120499774631\n",
            "For learning rate :0.00175\n",
            "The RMSE score for test dataset of Microclimateis: 0.14871268\n",
            "The R2 score for test dataset of Microclimateis: 0.9771763929077267\n",
            "For learning rate :0.002\n",
            "The RMSE score for test dataset of Microclimateis: 0.14461781\n",
            "The R2 score for test dataset of Microclimateis: 0.9784160056388996\n",
            "For learning rate :0.003\n",
            "The RMSE score for test dataset of Microclimateis: 0.14986454\n",
            "The R2 score for test dataset of Microclimateis: 0.9768214586978001\n",
            "For learning rate :0.01\n",
            "The RMSE score for test dataset of Microclimateis: 0.14921732\n",
            "The R2 score for test dataset of Microclimateis: 0.9770212275039487\n",
            "For final learning rate :0.002\n",
            "The RMSE score for test dataset of Microclimate is: 0.14461781\n",
            "The R2 score for test dataset of Microclimate is: 0.9784160056388996\n",
            "The RMSE score for test dataset of Weatherstationis: 0.52656347\n",
            "The R2 score for test dataset of Weatherstationis: 0.7227668516652519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43054f94"
      },
      "source": [
        " "
      ],
      "id": "43054f94"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c0ae8a2"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "id": "7c0ae8a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXFEcS2RDv6F"
      },
      "source": [
        ""
      ],
      "id": "JXFEcS2RDv6F",
      "execution_count": null,
      "outputs": []
    }
  ]
}