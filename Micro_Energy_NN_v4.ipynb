{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c60a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1539d50",
   "metadata": {},
   "source": [
    "## Flow of Code:\n",
    "#### 1. Read both datasets, and do data preparation: Scaling, One-hot Encoding\n",
    "#### 2. For limited data, train  model on Temp, Hum, Dsw(4), Shade(4), Encoding input features (find hyperparameters analytically)\n",
    "#### 3. For big data, train model on Temp, Hum, Encoding \n",
    "#### 4. Fine tune weather station model on microclimate data and compare performance\n",
    "#### 5. Work on adding artificial features and dropout on microclimate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c914ba15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "\n",
    "%reload_ext tensorboard\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.keras import initializers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pickle\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import tensorboard\n",
    "tensorboard.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f803fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self,activation_type, hidden_layers, loss, kernel_initializer, bias_initializer, data_type,epochs):\n",
    "        self.activation_type = activation_type\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.loss = loss\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer \n",
    "        self.data_type = data_type\n",
    "        self.epochs = epochs\n",
    "    def huber_loss(y_true, y_pred, clip_delta=1.0):\n",
    "        error = y_true - y_pred\n",
    "        cond  = tf.keras.backend.abs(error) < clip_delta\n",
    "        squared_loss = 0.5 * tf.keras.backend.square(error)\n",
    "        linear_loss  = clip_delta * (tf.keras.backend.abs(error) - 0.5 * clip_delta)\n",
    "        return tf.where(cond, squared_loss, linear_loss)\n",
    "    def huber_loss_mean(y_true, y_pred, clip_delta=1.0):\n",
    "        return tf.keras.backend.mean(huber_loss(y_true, y_pred, clip_delta))\n",
    "    def prepare_data(self, dataset, func):\n",
    "        Y = dataset['CHWTON/SQFT']\n",
    "        if self.data_type == 'WeatherStation'  and (func == 'test' or func == 'train'):\n",
    "            X = dataset[['Air Temp', 'Abs Hum']]\n",
    "        if self.data_type == 'Microclimate' and func == 'train':\n",
    "            X = dataset[['Air Temp', \n",
    "                         'Abs Hum', \n",
    "                         'DSW North', \n",
    "                         'DSW South', \n",
    "                         'DSW East', \n",
    "                         'DSW West', \n",
    "                         'Shade North', \n",
    "                         'Shade East', \n",
    "                         'Shade West',\n",
    "                         'Shade South']]\n",
    "        if self.data_type == 'Microclimate' and func == 'test':\n",
    "            X = dataset[['Air Temp', \n",
    "                         'Abs Hum']]\n",
    "        X_bldg_name = dataset[['bldgname']]\n",
    "        Y = Y.values.reshape(-1, 1)\n",
    "        #create one-hot encoding for all buildings\n",
    "        one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "        one_hot_encoder.fit(X_bldg_name)\n",
    "        X_bldg_name_encoded = one_hot_encoder.transform(X_bldg_name)\n",
    "        X_bldg_name_encoded = pd.DataFrame(data=X_bldg_name_encoded, columns=one_hot_encoder.categories_)\n",
    "        X_bldg_name_encoded = np.asarray(X_bldg_name_encoded).astype('float32')\n",
    "        # Normalize input and target values\n",
    "        scaler1 = StandardScaler()\n",
    "        X_scaled = scaler1.fit_transform(X)\n",
    "        scaler2 = StandardScaler()\n",
    "        Y_scaled = scaler2.fit_transform(Y)\n",
    "        # add categorical to numeric data\n",
    "        X_final = np.concatenate((X_bldg_name_encoded, X_scaled), axis =1)\n",
    "        X_final = np.asarray(X_final).astype('float32')\n",
    "        Y_scaled = np.asarray(Y_scaled).astype('float32')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_final, Y_scaled, \n",
    "                                                           test_size=0.2, \n",
    "                                                           random_state=20)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    def define_model(self):\n",
    "        if self.data_type == 'WeatherStation' :\n",
    "            model = Sequential()\n",
    "            if self.activation_type == 'leaky_relu':\n",
    "                model.add(Dense(20, \n",
    "                                input_dim=13, \n",
    "                                kernel_initializer=self.kernel_initializer, \n",
    "                                bias_initializer=self.bias_initializer, \n",
    "                                activation= self.activation_type))\n",
    "                for i in range(0,(self.hidden_layers-2)):\n",
    "                    model.add(Dense(30, activation = self.activation_type))\n",
    "                model.add(Dense(20, activation = self.activation_type))\n",
    "                model.add(Dense(1, activation = 'linear'))\n",
    "            else:\n",
    "                model.add(Dense(30, \n",
    "                                input_dim=13, \n",
    "                                kernel_initializer=self.kernel_initializer, \n",
    "                                bias_initializer=self.bias_initializer, \n",
    "                                activation= self.activation_type))\n",
    "                for i in range(0,(self.hidden_layers-2)):\n",
    "                    model.add(Dense(40, activation = self.activation_type))\n",
    "                model.add(Dense(20, activation = self.activation_type))\n",
    "                model.add(Dense(1, activation = 'linear'))\n",
    "            \n",
    "            \n",
    "        if self.data_type == 'Microclimate':\n",
    "            model = Sequential()\n",
    "            if self.activation_type == 'leaky_relu':\n",
    "                model.add(Dense(30, \n",
    "                                input_dim=21, \n",
    "                                kernel_initializer=self.kernel_initializer, \n",
    "                                bias_initializer=self.bias_initializer, \n",
    "                                activation= self.activation_type))\n",
    "                for i in range(0,(self.hidden_layers-2)):\n",
    "                    model.add(Dense(40, activation = self.activation_type))\n",
    "                model.add(Dense(20, activation = self.activation_type))\n",
    "                model.add(Dense(1, activation = 'linear'))\n",
    "            else:\n",
    "                model.add(Dense(30, \n",
    "                                input_dim=21, \n",
    "                                kernel_initializer=self.kernel_initializer, \n",
    "                                bias_initializer=self.bias_initializer, \n",
    "                                activation= self.activation_type))\n",
    "                for i in range(0,(self.hidden_layers-2)):\n",
    "                    model.add(Dense(40, activation = self.activation_type))\n",
    "                model.add(Dense(20, activation = self.activation_type))\n",
    "                model.add(Dense(1, activation = 'linear'))\n",
    "        model.compile( loss = self.loss, \n",
    "                      optimizer = 'adam')\n",
    "        model.summary()\n",
    "        return model\n",
    "    def train(self, dataset):\n",
    "        X_train, X_test, y_train, y_test = self.prepare_data(dataset,'train')\n",
    "        self.model = self.define_model()\n",
    "        # Define the Keras TensorBoard callback.\n",
    "        logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "        self.history = self.model.fit(X_train,y_train, \n",
    "                            batch_size=128, \n",
    "                            epochs=self.epochs, \n",
    "                            verbose=0, \n",
    "                            validation_split=0.2, \n",
    "                            callbacks=[tensorboard_callback])\n",
    "    def fine_tune(self, dataset):\n",
    "        self.model.trainable = True\n",
    "        fine_tune_at = 2\n",
    "        for layer in self.model.layers[:fine_tune_at]:\n",
    "            layer.trainable =  False\n",
    "        self.model.compile(loss=self.loss, \n",
    "                           optimizer='adam')\n",
    "        X_train, X_test, y_train, y_test = self.prepare_data(dataset,'test')\n",
    "        # Define the Keras TensorBoard callback.\n",
    "        logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "        self.history = self.model.fit(X_train,y_train, \n",
    "                            batch_size=128, \n",
    "                            epochs=self.epochs, \n",
    "                            verbose=0, \n",
    "                            validation_split=0.2, \n",
    "                            callbacks=[tensorboard_callback])\n",
    "        \n",
    "        \n",
    "    def plot_curve(self):\n",
    "        plt.plot(self.history.history['loss'])\n",
    "        plt.plot(self.history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'validation'], loc='upper left')\n",
    "        plt.show()\n",
    "    def evaluate(self, dataset, data_type ):\n",
    "        call_type = 'test'\n",
    "        if data_type == self.data_type:\n",
    "            call_type = 'train'\n",
    "        _, X_test, _, y_test = self.prepare_data(dataset,call_type)\n",
    "        Y_preds = self.model.predict(X_test)\n",
    "        RMSE = np.sqrt(metrics.mean_squared_error(y_test, Y_preds))\n",
    "        R2_score = metrics.r2_score(y_test, Y_preds)\n",
    "        print(\"The RMSE score for test dataset of \"+ data_type +\"is:\", RMSE)\n",
    "        print(\"The R2 score for test dataset of \"+ data_type +\"is:\", R2_score)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9b62c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 30)                660       \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 40)                1240      \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 4,381\n",
      "Trainable params: 4,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 00:15:59.265556: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "2021-10-29 00:15:59.265636: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0610s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 00:16:00.102251: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "2021-10-29 00:16:00.102322: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-10-29 00:16:00.157408: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:223]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2021-10-29 00:16:00.160692: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: logs/fit/20211029-001559/train/plugins/profile/2021_10_29_00_16_00\n",
      "2021-10-29 00:16:00.162209: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to logs/fit/20211029-001559/train/plugins/profile/2021_10_29_00_16_00/biswas.trace.json.gz\n",
      "2021-10-29 00:16:00.163823: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: logs/fit/20211029-001559/train/plugins/profile/2021_10_29_00_16_00\n",
      "2021-10-29 00:16:00.163913: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/20211029-001559/train/plugins/profile/2021_10_29_00_16_00/biswas.memory_profile.json.gz\n",
      "2021-10-29 00:16:00.164202: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: logs/fit/20211029-001559/train/plugins/profile/2021_10_29_00_16_00Dumped tool data for xplane.pb to logs/fit/20211029-001559/train/plugins/profile/2021_10_29_00_16_00/biswas.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fit/20211029-001559/train/plugins/profile/2021_10_29_00_16_00/biswas.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fit/20211029-001559/train/plugins/profile/2021_10_29_00_16_00/biswas.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fit/20211029-001559/train/plugins/profile/2021_10_29_00_16_00/biswas.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fit/20211029-001559/train/plugins/profile/2021_10_29_00_16_00/biswas.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE score for test dataset of Microclimateis: 0.13961779\n",
      "The R2 score for test dataset of Microclimateis: 0.9798826969943879\n"
     ]
    }
   ],
   "source": [
    "MicroclimateData = pd.read_csv('./all_buildings_limited.csv')\n",
    "WeatherStationData = pd.read_csv('./all_buildings_big.csv')\n",
    "if __name__ == \"__main__\":\n",
    "    # Train microclimate Model\n",
    "    MicroclimateModel = NeuralNetwork('relu',4, 'huber_loss', 'he_normal','he_normal', 'Microclimate', 200)\n",
    "    MicroclimateModel.train(MicroclimateData)\n",
    "    MicroclimateModel.evaluate(MicroclimateData, 'Microclimate')\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6744b60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 30)                420       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 40)                1240      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 4,141\n",
      "Trainable params: 4,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 00:17:00.914003: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "2021-10-29 00:17:00.914059: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0528s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 00:17:01.688106: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "2021-10-29 00:17:01.688213: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-10-29 00:17:01.720885: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:223]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2021-10-29 00:17:01.730258: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: logs/fit/20211029-001700/train/plugins/profile/2021_10_29_00_17_01\n",
      "2021-10-29 00:17:01.737240: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to logs/fit/20211029-001700/train/plugins/profile/2021_10_29_00_17_01/biswas.trace.json.gz\n",
      "2021-10-29 00:17:01.741221: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: logs/fit/20211029-001700/train/plugins/profile/2021_10_29_00_17_01\n",
      "2021-10-29 00:17:01.741398: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/20211029-001700/train/plugins/profile/2021_10_29_00_17_01/biswas.memory_profile.json.gz\n",
      "2021-10-29 00:17:01.741918: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: logs/fit/20211029-001700/train/plugins/profile/2021_10_29_00_17_01Dumped tool data for xplane.pb to logs/fit/20211029-001700/train/plugins/profile/2021_10_29_00_17_01/biswas.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fit/20211029-001700/train/plugins/profile/2021_10_29_00_17_01/biswas.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fit/20211029-001700/train/plugins/profile/2021_10_29_00_17_01/biswas.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fit/20211029-001700/train/plugins/profile/2021_10_29_00_17_01/biswas.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fit/20211029-001700/train/plugins/profile/2021_10_29_00_17_01/biswas.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE score for test dataset of Microclimateis: 0.5009891\n",
      "The R2 score for test dataset of Microclimateis: 0.7409731764138219\n"
     ]
    }
   ],
   "source": [
    "# Train Weather Station Model\n",
    "WeatherStationModel = NeuralNetwork('relu',4, 'huber_loss', 'he_normal','he_normal', 'WeatherStation', 100)\n",
    "WeatherStationModel.train(WeatherStationData)\n",
    "WeatherStationModel.evaluate(MicroclimateData, 'Microclimate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00f1e303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 00:22:04.974229: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "2021-10-29 00:22:04.974303: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0535s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 00:22:05.736087: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "2021-10-29 00:22:05.736177: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "2021-10-29 00:22:05.783886: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:223]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2021-10-29 00:22:05.787130: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: logs/fit/20211029-002204/train/plugins/profile/2021_10_29_00_22_05\n",
      "2021-10-29 00:22:05.788484: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to logs/fit/20211029-002204/train/plugins/profile/2021_10_29_00_22_05/biswas.trace.json.gz\n",
      "2021-10-29 00:22:05.790039: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: logs/fit/20211029-002204/train/plugins/profile/2021_10_29_00_22_05\n",
      "2021-10-29 00:22:05.790163: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/20211029-002204/train/plugins/profile/2021_10_29_00_22_05/biswas.memory_profile.json.gz\n",
      "2021-10-29 00:22:05.790467: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: logs/fit/20211029-002204/train/plugins/profile/2021_10_29_00_22_05Dumped tool data for xplane.pb to logs/fit/20211029-002204/train/plugins/profile/2021_10_29_00_22_05/biswas.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fit/20211029-002204/train/plugins/profile/2021_10_29_00_22_05/biswas.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fit/20211029-002204/train/plugins/profile/2021_10_29_00_22_05/biswas.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fit/20211029-002204/train/plugins/profile/2021_10_29_00_22_05/biswas.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fit/20211029-002204/train/plugins/profile/2021_10_29_00_22_05/biswas.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE score for test dataset of Microclimateis: 0.15505601\n",
      "The R2 score for test dataset of Microclimateis: 0.975187784048241\n",
      "The RMSE score for test dataset of WeatherStationis: 0.5142654\n",
      "The R2 score for test dataset of WeatherStationis: 0.7355653470084045\n"
     ]
    }
   ],
   "source": [
    "# Fine Tune and compare results\n",
    "WeatherStationModel.fine_tune(MicroclimateData)\n",
    "WeatherStationModel.evaluate(MicroclimateData, 'Microclimate')\n",
    "WeatherStationModel.evaluate(WeatherStationData, 'WeatherStation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43054f94",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c0ae8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "Traceback (most recent call last):\n",
       "  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n",
       "    from tensorboard.tensorboard.main import *\n",
       "ModuleNotFoundError: No module named 'tensorboard'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95975ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
